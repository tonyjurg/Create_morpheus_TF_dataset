{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72cc1e6-193a-49c4-b56f-a40c365e7623",
   "metadata": {},
   "source": [
    "# Morpheus Morphological Parser & JSON Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0645447-18a6-4ce3-8dc4-58205a951171",
   "metadata": {},
   "source": [
    "## Table of content (ToC)<a class=\"anchor\" id=\"TOC\"></a>\n",
    "* <a href=\"#bullet1\">1 - Introduction</a>\n",
    "* <a href=\"#bullet2\">2 - The code</a>\n",
    "    * <a href=\"#bullet2x1\">2.1 - Read the morpheus outputfile</a>\n",
    "    * <a href=\"#bullet2x2\">2.2 - Parse each entry and gather morphological elements</a>\n",
    "    * <a href=\"#bullet2x3\">2.3 - Run on a File & Export JSON</a>\n",
    "    * <a href=\"#bullet2x4\">2.4 - Run on a File & Export JSON</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5462129",
   "metadata": {},
   "source": [
    "# 1 - Introduction  <a class=\"anchor\" id=\"bullet1\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "This notebook reads the full Morpheus output (plain‑text format), parses each word’s block,\n",
    "extracts all morphological details, classifies part of speech (POS), converts Beta Code to\n",
    "Unicode, and finally exports one comprehensive JSON file mapping every input word to all\n",
    "its parses.\n",
    "\n",
    "The logic in this notebook is based upon my deconstruction of the morpheus output as detailed in [this document](decode_output.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb2810-07cb-4339-ba8d-8bc1eb5480b3",
   "metadata": {},
   "source": [
    "# 2 - The code  <a class=\"anchor\" id=\"bullet2\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "\n",
    "The key parts of the code in this notebook are:\n",
    "\n",
    " - Read the morpheus outputfile and split the raw output into entries (one per word).\n",
    " - Parse each entry and gather every morphological element (lemma, stem, ending, tense, voice, mood, person, case, gender, number, degree, dialect, variant, inflection class, etc.).  \n",
    " - Build a Python dict (`parsed_data`) mapping each input word to a list of parse dictionaries, then  dump it as nicely‑formatted JSON.\n",
    "\n",
    "The code is fully modular and commented for maintainability and expantion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742622d4-3411-4e7d-9af9-01e3627fc259",
   "metadata": {},
   "source": [
    "## 2.1 - Read the morpheus outputfile\n",
    "\n",
    "This is part 1; it reads the morpheus outputfile and splits the raw output into entries (one per word). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c8a7bd8-6be3-449c-b200-d59381138caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 19446 word entries from gnt_morphology_results.txt\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "input_file = 'gnt_morphology_results.txt'   #  path to raw Morpheus output\n",
    "assert pathlib.Path(input_file).exists(), f\"Input file not found: {input_file}\"\n",
    "\n",
    "word_blocks = []\n",
    "current_block = []\n",
    "with open(input_file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip('\\n')\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith('Word:'):\n",
    "            if current_block:\n",
    "                word_blocks.append(current_block)\n",
    "            current_block = [line]\n",
    "        elif line.startswith('----------------'):\n",
    "            if current_block:\n",
    "                word_blocks.append(current_block)\n",
    "            current_block = []\n",
    "        else:\n",
    "            current_block.append(line)\n",
    "    if current_block:\n",
    "        word_blocks.append(current_block)\n",
    "\n",
    "print(f'Read {len(word_blocks)} word entries from {input_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6badc66c-11ce-49ea-b98b-39b23ad3b3a7",
   "metadata": {},
   "source": [
    "## 2.2 - Parse each block and gather its elements <a class=\"anchor\" id=\"bullet2x2\"></a>\n",
    "\n",
    "This is part 2 and it is realy the meat to the bone; the engine. Here we parse each entry and gather every morphological element (lemma, stem, ending, tense, voice, mood, person, case, gender, number, degree, dialect, variant, inflection class, etc.). It also gathers specific details on POS, when pressent. The most tricky parts is the chained if-elif section, which will be commented heavily in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cf074ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_word_block(block):\n",
    "    header=block[0]\n",
    "    word_beta=header.split('Word:',1)[1].strip()\n",
    "    if len(block)>1 and block[1].startswith('Error:'):\n",
    "        return word_beta,[]\n",
    "    parses=[]; current=None\n",
    "    for line in block[1:]:\n",
    "        if not line.startswith(':'): continue\n",
    "        label=line.split()[0][1:]\n",
    "        fields=line[len(label)+2:].split('\\t')\n",
    "        if label=='raw':\n",
    "            current={'raw_beta':fields[0].strip()}\n",
    "            parses.append(current)\n",
    "        elif current is None: continue\n",
    "\n",
    "        \n",
    "# ---------------------------------------------------------------\n",
    "# :workw  ― “working word” (Morpheus-normalised token)\n",
    "# ---------------------------------------------------------------\n",
    "        \n",
    "        elif label == \"workw\":\n",
    "            # Column-0 holds the token that Morpheus actually analysed.\n",
    "            # Typical differences from :raw:\n",
    "            #   a leading asterisk (capital mark) may be removed\n",
    "            #   accents might be regularised\n",
    "            #   elision/apostrophe may be expanded when Morpheus is run with the –S switch\n",
    "            work_token = fields[0].strip()           # e.g.  le/gete  vs  *le/gete\n",
    "            current[\"work_beta\"] = work_token        # keep Beta-Code form\n",
    "\n",
    "            # Unicode copy for readability\n",
    "            current[\"work_unicode\"] = beta_code.beta_code_to_greek(work_token)\n",
    "\n",
    "        \n",
    "# ---------------------------------------------------------------\n",
    "# :lem  ― handle lemma, homonym tag, and Unicode copies\n",
    "# ---------------------------------------------------------------\n",
    "        \n",
    "        elif label == \"lem\":\n",
    "            # col-0  = lemma in Beta-Code, possibly with numeric suffix\n",
    "            #          e.g.  'le/gw1'  or  'h)/2'\n",
    "            lemma_field = fields[0].strip()\n",
    "\n",
    "            # Always keep the *full* lemma (including any numeric sense tag)\n",
    "            current[\"lemma_beta\"] = lemma_field\n",
    "\n",
    "            # -----------------------------------------------------------\n",
    "            # Detect homonymous lemmas   (pattern: <lemma><digits>)\n",
    "            #   group(1) → base lemma   (le/gw)\n",
    "            #   group(2) → digits       (1)\n",
    "            # -----------------------------------------------------------\n",
    "            m = re.match(r\"^(.*?)(\\d+)$\", lemma_field)\n",
    "            if m:\n",
    "                current[\"lemma_base\"] = m.group(1)          # le/gw\n",
    "                current[\"homonym\"]    = int(m.group(2))     # 1  (as int)\n",
    "            else:\n",
    "                # No numeric suffix → single-sense lemma\n",
    "                current[\"lemma_base\"] = lemma_field\n",
    "\n",
    "            # -----------------------------------------------------------\n",
    "            # Unicode copies for readability\n",
    "            # -----------------------------------------------------------\n",
    "            current[\"lemma_unicode\"]       = beta_code.beta_code_to_greek(lemma_field)\n",
    "            current[\"lemma_base_unicode\"]  = beta_code.beta_code_to_greek(\n",
    "                current[\"lemma_base\"]\n",
    "            )\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# :prvb / :aug1 / :suff   ― 5-column layout\n",
    "#   col-0  ⇒ preverb / augment / suffix  (betacode segment)\n",
    "#   col-2  ⇒ dialect                    (may list several)\n",
    "#   col-3  ⇒ morph-flags                (space-separated)\n",
    "# ------------------------------------------------------------------\n",
    "        \n",
    "        elif label in {\"prvb\", \"aug1\", \"suff\"}:\n",
    "            key_map = {\"prvb\": \"preverb_beta\",\n",
    "                       \"aug1\": \"augment_beta\",\n",
    "                       \"suff\": \"suffix_beta\"}\n",
    "            key = key_map[label]\n",
    "        \n",
    "            # --- col-0: β-code segment (may be empty) ----------------------\n",
    "            segment = fields[0].strip()\n",
    "            if segment:\n",
    "                # For :prvb you can get multiple prepositions separated by commas\n",
    "                # (e.g. \"dia/,kata/\").  Store as list for convenience; otherwise keep str.\n",
    "                current[key] = (\n",
    "                    [s for s in re.split(r\"[ ,]+\", segment) if s] if label == \"prvb\" else segment\n",
    "                )\n",
    "        \n",
    "            # --- col-2: dialect(s) ----------------------------------------\n",
    "            if len(fields) > 2 and fields[2].strip():\n",
    "                current.setdefault(\"dialects\", []).extend(fields[2].strip().split())\n",
    "        \n",
    "            # --- col-3: morph-flags ---------------------------------------\n",
    "            if len(fields) > 3 and fields[3].strip():\n",
    "                current.setdefault(\"morph_flags\", []).extend(fields[3].strip().split())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# :stem  ― 5-column layout\n",
    "#   col-0  stem segment  (β-code)            → stem_beta / stem_unicode\n",
    "#   col-1  inherent morpho-syntax            → gender / number / case …\n",
    "#   col-2  dialect(s)                        → dialects  (list)\n",
    "#   col-3  morph-flags                       → morph_flags  (list)\n",
    "#   col-4  stem-type / paradigm code(s)      → morph_codes  (list)\n",
    "# ---------------------------------------------------------------\n",
    "        \n",
    "        elif label == \"stem\":\n",
    "\n",
    "            # ── col-0: stem segment (always first) ────────────────────\n",
    "            stem_segment = fields[0].strip()\n",
    "            if stem_segment:\n",
    "                current[\"stem_beta\"]    = stem_segment\n",
    "                current[\"stem_unicode\"] = beta_code.beta_code_to_greek(stem_segment)\n",
    "\n",
    "            # ── col-1: inherent morpho-syntax (optional) ──────────────\n",
    "            #     Examples: \"fem\", \"masc sg\", \"mp\", \"nom/voc sg\"\n",
    "            if len(fields) > 1 and fields[1]:\n",
    "                for tok in fields[1].split():\n",
    "                    if tok in {\"masc\", \"fem\", \"neut\"}:\n",
    "                        current[\"gender\"] = tok\n",
    "                    elif tok in {\"sg\", \"pl\", \"dual\"}:\n",
    "                        current[\"number\"] = tok\n",
    "                    elif tok in {\"nom\", \"acc\", \"gen\", \"dat\", \"voc\"}:\n",
    "                        current[\"case\"] = tok\n",
    "                    else:\n",
    "                        # Catch-all: any uncommon token (e.g. \"mp\", \"indeclform\")\n",
    "                        # is treated as an extra morph-flag.\n",
    "                        current.setdefault(\"morph_flags\", []).append(tok)\n",
    "\n",
    "            # ── col-2: dialect markers (optional) ─────────────────────\n",
    "            if len(fields) > 2 and fields[2].strip():\n",
    "                current.setdefault(\"dialects\", []).extend(\n",
    "                    fields[2].strip().split()\n",
    "                )\n",
    "\n",
    "            # ── col-3: other morph-flags (optional) ───────────────────\n",
    "            if len(fields) > 3 and fields[3].strip():\n",
    "                current.setdefault(\"morph_flags\", []).extend(\n",
    "                    fields[3].strip().split()\n",
    "                )\n",
    "\n",
    "            # ── col-4: stem-type / paradigm codes (optional) ──────────\n",
    "            #     E.g. \"os_h_on\", \"aor2\", \"mi_pr\"  (comma-separated list)\n",
    "            if len(fields) > 4 and fields[4].strip():\n",
    "                codes = [c.strip() for c in fields[4].split(\",\") if c.strip()]\n",
    "                current.setdefault(\"morph_codes\", []).extend(codes)\n",
    "\n",
    "      \n",
    "# ---------------------------------------------------------------\n",
    "# :end  ― 5-column layout (most detailed line)\n",
    "#   col-0  ending segment (β-code)                 → ending_beta / ending_unicode\n",
    "#   col-1  full morphological feature string       → tense / mood / …  (parsed below)\n",
    "#   col-2  dialect(s)  (optional)                  → dialects   (list)\n",
    "#   col-3  morph-flags (optional)                  → morph_flags  (list)\n",
    "#   col-4  paradigm / POS / extra codes (optional) → morph_codes  (list)\n",
    "# ---------------------------------------------------------------\n",
    "        \n",
    "        elif label == \"end\":\n",
    "\n",
    "            # ── col-0: ending segment ─────────────────────────────────\n",
    "            if fields[0]:\n",
    "                ending_seg = fields[0].strip()\n",
    "                current[\"ending_beta\"]    = ending_seg\n",
    "                current[\"ending_unicode\"] = beta_code.beta_code_to_greek(ending_seg)\n",
    "\n",
    "            # ── col-1: morphological feature tokens ──────────────────\n",
    "            if len(fields) > 1 and fields[1]:\n",
    "                for tok in fields[1].split():\n",
    "                    tl = tok.lower()            # normalised for matching\n",
    "\n",
    "                    # ----------------- verbal tense ------------------\n",
    "                    if tl in {\"pres\", \"present\"}:\n",
    "                        current[\"tense\"] = \"present\"\n",
    "                    elif tl in {\"imperf\", \"imperfect\"}:\n",
    "                        current[\"tense\"] = \"imperfect\"\n",
    "                    elif tl in {\"fut\", \"future\"}:\n",
    "                        current[\"tense\"] = \"future\"\n",
    "                    elif tl in {\"aor\", \"aorist\"}:\n",
    "                        current[\"tense\"] = \"aorist\"\n",
    "                    elif tl in {\"perf\", \"perfect\"}:\n",
    "                        current[\"tense\"] = \"perfect\"\n",
    "                    elif tl in {\"plup\", \"pluperfect\"}:\n",
    "                        current[\"tense\"] = \"pluperfect\"\n",
    "\n",
    "                    # ----------------- verbal mood -------------------\n",
    "                    elif tl in {\"ind\", \"indicative\"}:\n",
    "                        current[\"mood\"] = \"indicative\"\n",
    "                    elif tl in {\"subj\", \"subjunctive\"}:\n",
    "                        current[\"mood\"] = \"subjunctive\"\n",
    "                    elif tl in {\"opt\", \"optative\"}:\n",
    "                        current[\"mood\"] = \"optative\"\n",
    "                    elif tl in {\"imperat\", \"imperative\"}:\n",
    "                        current[\"mood\"] = \"imperative\"\n",
    "                    elif tl in {\"inf\", \"infinitive\"}:\n",
    "                        current[\"mood\"] = \"infinitive\"\n",
    "                    elif tl in {\"part\", \"participle\"}:\n",
    "                        current[\"mood\"] = \"participle\"\n",
    "\n",
    "                    # ----------------- verbal voice ------------------\n",
    "                    elif tl in {\"act\", \"active\"}:\n",
    "                        current[\"voice\"] = \"active\"\n",
    "                    elif tl in {\"mid\", \"middle\"}:\n",
    "                        current[\"voice\"] = \"middle\"\n",
    "                    elif tl in {\"pass\", \"passive\"}:\n",
    "                        current[\"voice\"] = \"passive\"\n",
    "                    elif tl == \"mp\":\n",
    "                        current[\"voice\"] = \"middle/passive\"\n",
    "\n",
    "                    # ---------------- person / number ----------------\n",
    "                    elif tl in {\"sg\", \"pl\", \"dual\"}:\n",
    "                        current[\"number\"] = tl\n",
    "                    elif re.match(r\"^[123]$\", tl):   # 1, 2, 3\n",
    "                        current[\"person\"] = tl\n",
    "\n",
    "                    # ---------------- gender / case ------------------\n",
    "                    elif tl in {\"masc\", \"fem\", \"neut\"}:\n",
    "                        current[\"gender\"] = tl\n",
    "                    elif tl in {\"nom\", \"acc\", \"gen\", \"dat\", \"voc\"}:\n",
    "                        # Handle combined cases like nom/voc/acc\n",
    "                        if \"/\" in tok:\n",
    "                            current.setdefault(\"case\", []).extend(tok.split(\"/\"))\n",
    "                        else:\n",
    "                            current[\"case\"] = tl\n",
    "\n",
    "                    # --------------- degree (comparatives) -----------\n",
    "                    elif tl in {\"comp\", \"comparative\"}:\n",
    "                        current[\"degree\"] = \"comparative\"\n",
    "                    elif tl in {\"sup\", \"superlative\"}:\n",
    "                        current[\"degree\"] = \"superlative\"\n",
    "\n",
    "                    # --------------- fallback: keep unknowns ---------\n",
    "                    else:\n",
    "                        # Anything unrecognised is saved so nothing is lost\n",
    "                        current.setdefault(\"other_end_tokens\", []).append(tok)\n",
    "\n",
    "            # ── col-2: dialects ──────────────────────────────────────\n",
    "            if len(fields) > 2 and fields[2].strip():\n",
    "                current.setdefault(\"dialects\", []).extend(\n",
    "                    fields[2].strip().split()\n",
    "                )\n",
    "\n",
    "            # ── col-3: morph-flags (e.g. contr, enclitic) ────────────\n",
    "            if len(fields) > 3 and fields[3].strip():\n",
    "                current.setdefault(\"morph_flags\", []).extend(\n",
    "                    fields[3].strip().split()\n",
    "                )\n",
    "\n",
    "            # ── col-4: paradigm / POS / extra codes ──────────────────\n",
    "            if len(fields) > 4 and fields[4].strip():\n",
    "                codes = [c.strip() for c in fields[4].split(\",\") if c.strip()]\n",
    "                current.setdefault(\"morph_codes\", []).extend(codes)\n",
    "                \n",
    "    return word_beta, parses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84932e-5c06-4616-838f-4a541a9c6ec2",
   "metadata": {},
   "source": [
    "## 2.3 - Parse all blocks <a class=\"anchor\" id=\"bullet2x3\"></a>\n",
    "\n",
    "Recursive call the previous function to process all blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28a2ce84-52a1-4b4b-8a81-914b1136a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data={}\n",
    "for blk in word_blocks:\n",
    "    w,p=parse_word_block(blk)\n",
    "    parsed_data[w]=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39ca1754-7b18-4448-908a-875e0708d03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kai\\ -> [{'raw_beta': 'kai\\\\', 'work_beta': 'kai/', 'work_unicode': 'καί', 'lemma_beta': 'kai/', 'lemma_base': 'kai/', 'lemma_unicode': 'καί', 'lemma_base_unicode': 'καί', 'stem_beta': 'kai/', 'stem_unicode': 'καί', 'morph_flags': ['indeclform', 'indeclform'], 'morph_codes': ['conj']}] \n",
      "\n",
      "\n",
      "o( -> [{'raw_beta': 'o(', 'work_beta': 'o(', 'work_unicode': 'ὁ', 'lemma_beta': 'o(', 'lemma_base': 'o(', 'lemma_unicode': 'ὁ', 'lemma_base_unicode': 'ὁ', 'stem_beta': 'o(', 'stem_unicode': 'ὁ', 'morph_flags': ['proclitic', 'indeclform', 'proclitic', 'indeclform'], 'gender': 'masc', 'case': 'nom', 'number': 'sg', 'morph_codes': ['article']}] \n",
      "\n",
      "\n",
      "e)n -> [{'raw_beta': 'e)n', 'work_beta': 'e)n', 'work_unicode': 'ἐν', 'lemma_beta': 'e)n', 'lemma_base': 'e)n', 'lemma_unicode': 'ἐν', 'lemma_base_unicode': 'ἐν', 'stem_beta': 'e)n', 'stem_unicode': 'ἐν', 'morph_flags': ['proclitic', 'indeclform', 'proclitic', 'indeclform'], 'morph_codes': ['prep']}, {'raw_beta': 'e)n', 'work_beta': 'e)n', 'work_unicode': 'ἐν', 'lemma_beta': 'ei)s', 'lemma_base': 'ei)s', 'lemma_unicode': 'εἰς', 'lemma_base_unicode': 'εἰς', 'stem_beta': 'e)n', 'stem_unicode': 'ἐν', 'morph_flags': ['proclitic', 'indeclform', 'proclitic', 'indeclform'], 'dialects': ['doric', 'aeolic'], 'morph_codes': ['prep']}] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Just to check the output\n",
    "from itertools import islice\n",
    "sample = dict(islice(parsed_data.items(), 3))\n",
    "for w, parses in sample.items():\n",
    "    print(w, \"->\", parses[:2], \"\\n\\n\")   # prints only the first three parses for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cafd0d-f9c6-458b-84d4-d5e200725582",
   "metadata": {},
   "source": [
    "## 2.4 - Unicode and POS <a class=\"anchor\" id=\"bullet2x4\"></a>\n",
    "\n",
    "Perform the Unicode conversion and determing the POS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b4d7696-4f04-41a1-adce-d00edaee252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import beta_code\n",
    "\n",
    "# I have to realy make this uniform! T\n",
    "pos_map={'conj':'conj','adv':'adverb','prep':'prep'}\n",
    "pos_labels={'noun','verb','adjective','adverb','conj','prep',\n",
    "            'pron','part','art','participle'}\n",
    "for w,plist in parsed_data.items():\n",
    "    for p in plist:\n",
    "        \n",
    "        # Convert Betacode to Unicode for key fields\n",
    "        for k in [\n",
    "            \"raw_beta\", \"work_beta\", \"lemma_beta\", \"preverb_beta\", \"augment_beta\",\n",
    "            \"stem_beta\", \"suffix_beta\", \"ending_beta\"\n",
    "        ]:\n",
    "            if k not in p:\n",
    "                continue\n",
    "        \n",
    "            value = p[k]\n",
    "        \n",
    "            if isinstance(value, list):\n",
    "                # Convert every element in the list\n",
    "                p[k.replace(\"_beta\", \"_unicode\")] = [\n",
    "                    beta_code.beta_code_to_greek(x) for x in value\n",
    "                ]\n",
    "            elif isinstance(value, str):\n",
    "                # Single string → single string\n",
    "                p[k.replace(\"_beta\", \"_unicode\")] = beta_code.beta_code_to_greek(value)\n",
    "        \n",
    "        # determening the POS (still to be tweaked...)\n",
    "        pos=None\n",
    "        for code in p.get('morph_codes',[]):\n",
    "            if code.lower() in pos_map: pos=pos_map[code.lower()]\n",
    "            elif code.lower() in pos_labels: pos=code.lower()\n",
    "            # order matters here????\n",
    "            if code.lower()=='article': pos='art'\n",
    "            if code.lower()=='particle': pos='part'\n",
    "        if pos is None:\n",
    "            if any(k in p for k in ('tense','mood','voice','person')):\n",
    "                pos='participle' if p.get('mood')=='participle' or 'case' in p else 'verb'\n",
    "            elif any(k in p for k in ('case','gender','number')):\n",
    "                pos='article' if 'article' in p.get('morph_codes',[]) else 'noun'\n",
    "            else:\n",
    "                pos='part'\n",
    "        p['POS']=pos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047dfc9-b9b4-4adb-a0e2-afd6a13c780c",
   "metadata": {},
   "source": [
    "## Check the results\n",
    "\n",
    "The following code gives a quick review & some statistics on the produced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcbdf9ac-a85a-4367-b497-083c635760d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== First 5 parses ===\n",
      "word_beta word_unicode  POS raw_beta work_beta work_unicode lemma_beta lemma_base lemma_unicode lemma_base_unicode stem_beta stem_unicode                                    morph_flags morph_codes raw_unicode gender case number        dialects other_end_tokens ending_beta ending_unicode  homonym tense mood voice augment_beta augment_unicode preverb_beta preverb_unicode degree\n",
      "     kai\\          καὶ conj     kai\\      kai/          καί       kai/       kai/           καί                καί      kai/          καί                       [indeclform, indeclform]      [conj]         καὶ    NaN  NaN    NaN             NaN              NaN         NaN            NaN      NaN   NaN  NaN   NaN          NaN             NaN          NaN             NaN    NaN\n",
      "       o(            ὁ  art       o(        o(            ὁ         o(         o(             ὁ                  ὁ        o(            ὁ [proclitic, indeclform, proclitic, indeclform]   [article]           ὁ   masc  nom     sg             NaN              NaN         NaN            NaN      NaN   NaN  NaN   NaN          NaN             NaN          NaN             NaN    NaN\n",
      "      e)n           ἐν prep      e)n       e)n           ἐν        e)n        e)n            ἐν                 ἐν       e)n           ἐν [proclitic, indeclform, proclitic, indeclform]      [prep]          ἐν    NaN  NaN    NaN             NaN              NaN         NaN            NaN      NaN   NaN  NaN   NaN          NaN             NaN          NaN             NaN    NaN\n",
      "      e)n           ἐν prep      e)n       e)n           ἐν       ei)s       ei)s           εἰς                εἰς       e)n           ἐν [proclitic, indeclform, proclitic, indeclform]      [prep]          ἐν    NaN  NaN    NaN [doric, aeolic]              NaN         NaN            NaN      NaN   NaN  NaN   NaN          NaN             NaN          NaN             NaN    NaN\n",
      "      de\\           δὲ part      de\\       de/           δέ        de/        de/            δέ                 δέ       de/           δέ                       [indeclform, indeclform]  [particle]          δὲ    NaN  NaN    NaN             NaN              NaN         NaN            NaN      NaN   NaN  NaN   NaN          NaN             NaN          NaN             NaN    NaN\n",
      "\n",
      "=== POS distribution (value counts) ===\n",
      "POS\n",
      "verb          17509\n",
      "noun          12576\n",
      "participle     5749\n",
      "adverb          304\n",
      "part            248\n",
      "prep             69\n",
      "conj             60\n",
      "art              59\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Top 10 case/number/gender patterns ===\n",
      " nom/sg     /masc  →   1645\n",
      " acc/sg     /masc  →   1173\n",
      " acc/sg     /fem   →    935\n",
      " dat/sg     /fem   →    927\n",
      " gen/sg     /fem   →    834\n",
      " acc/pl     /masc  →    608\n",
      " acc/pl     /fem   →    522\n",
      " voc/sg     /masc  →    418\n",
      " gen/pl     /fem   →    380\n",
      " gen/sg     /masc  →    338\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "# Flatten the parsed_data by converting to a list[dict]\n",
    "flat_rows = []\n",
    "for beta_word, parses in parsed_data.items():\n",
    "    for p in parses:\n",
    "        row = {\n",
    "            \"word_beta\"   : beta_word,\n",
    "            \"word_unicode\": beta_code.beta_code_to_greek(beta_word),\n",
    "            \"POS\"         : p.get(\"POS\")\n",
    "        }\n",
    "        row.update(p)          # pull all parse fields in\n",
    "        flat_rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(flat_rows)\n",
    "\n",
    "# Peek at the first few rows\n",
    "print(\"\\n=== First 5 parses ===\")\n",
    "print(df.head(5).to_string(index=False))\n",
    "\n",
    "# Get some idea about POS distribution\n",
    "print(\"\\n=== POS distribution (value counts) ===\")\n",
    "print(df[\"POS\"].value_counts(dropna=False))\n",
    "\n",
    "# Get the most-frequent Case/Number/Gender combinations for  rows that actually have those three\n",
    "mask = df[[\"case\", \"number\", \"gender\"]].notna().all(axis=1)\n",
    "cng_counts = Counter(\n",
    "    tuple(df.loc[idx, [\"case\", \"number\", \"gender\"]])\n",
    "    for idx in df[mask].index\n",
    ")\n",
    "print(\"\\n=== Top 10 case/number/gender patterns ===\")\n",
    "for (case, num, gen), freq in islice(cng_counts.most_common(10), 10):\n",
    "    print(f\"{case:>4}/{num:<7}/{gen:<4}  → {freq:>6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf83531-dafd-4859-9d50-b94b23bb952b",
   "metadata": {},
   "source": [
    "## 2.5 - Export to JSON <a class=\"anchor\" id=\"bullet2x5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c40781c-02a9-455e-8c6e-f0c64b52d2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote JSON to morpheus_parses.json (19446 words).\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "out_path='morpheus_parses.json'\n",
    "with open(out_path,'w',encoding='utf-8') as jf:\n",
    "    json.dump(parsed_data,jf,ensure_ascii=False,indent=2)\n",
    "print(f'Wrote JSON to {out_path} ({len(parsed_data)} words).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccf402-88a9-45ed-9c3b-35cb2fdea0fc",
   "metadata": {},
   "source": [
    "# 3 - Acknowledgements <a class=\"anchor\" id=\"bullet3\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "This Jupyter notebook used the following sources for the analysis and implementation:\n",
    "\n",
    "- [Morpheus Morphological Analyzer (Perseus Project)](https://github.com/perseids-tools/morpheus/)\n",
    "- [Greek Beta Code standard](https://stephanus.tlg.uci.edu/encoding/BCM.pdf)\n",
    "- [beta-code-py](https://github.com/perseids-tools/beta-code-py)\n",
    "\n",
    "The [Anaconda Asisstant](https://www.anaconda.com/capability/anaconda-assistant) (using [OpenAI](https://openai.com/) as backend) was used to debug and/or optimze the code in this Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574dd64c-375a-407d-9ccb-41084c0da44b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4 - Required libraries <a class=\"anchor\" id=\"bullet4\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "The scripts in this notebook require Python 3.8+ and the following libraries to be installed in the environment:\n",
    "\n",
    "``` python\n",
    "    beta_code\n",
    "    json\n",
    "    pathlib\n",
    "```\n",
    "\n",
    "You can install any missing library from within Jupyter Notebook using either `pip` or `pip3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff02026-71c4-437f-bd96-0af6e85bafb6",
   "metadata": {},
   "source": [
    "# 5 - Notebook version details<a class=\"anchor\" id=\"bullet5\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "<div style=\"float: left;\">\n",
    "  <table>\n",
    "    <tr>\n",
    "      <td><strong>Author</strong></td>\n",
    "      <td>Tony Jurg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Version</strong></td>\n",
    "      <td>1.2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Date</strong></td>\n",
    "      <td>30 April 2025</td>\n",
    "    </tr>\n",
    "  </table>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
