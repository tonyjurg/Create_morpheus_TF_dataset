{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "023cc469-7019-4825-93b8-d684ea66424e",
   "metadata": {},
   "source": [
    "# Morpheus Morphological Extractor \\[OBSOLETE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d77d2-c51d-44d3-9038-d3cf6574e35d",
   "metadata": {},
   "source": [
    "## Table of content (ToC)<a class=\"anchor\" id=\"TOC\"></a>\n",
    "* <a href=\"#bullet1\">1 - Introduction</a>\n",
    "* <a href=\"#bullet2\">2 - The code</a>\n",
    "    * <a href=\"#bullet2x1\">2.1 - Read the morpheus outputfile</a>\n",
    "    * <a href=\"#bullet2x2\">2.2 - Parse each entry and gather morphological elements</a>\n",
    "    * <a href=\"#bullet2x3\">2.3 - Run on a File & Export JSON</a>\n",
    "    * <a href=\"#bullet2x4\">2.4 - Run on a File & Export JSON</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c54081",
   "metadata": {},
   "source": [
    "# 1 - Introduction <a class=\"anchor\" id=\"bullet1\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "This notebook extracts the morphological information from Morpheus output files and saves it\n",
    "in a structured JSON format. The code is NOT trying to guess or interpret part‑of‑speech (POS).  \n",
    "\n",
    "Note:\n",
    "> This notebook is now OBSOLETE because the functions in here are now much cleaner implemented in the package [morphkit](https://tonyjurg.github.io/morphkit/). Althoug in part based on the code in this notebook, the new package contains additinal functionality and various corrections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be270b03-0914-4608-82f4-c8b28c562546",
   "metadata": {},
   "source": [
    "# 2 - The code <a class=\"anchor\" id=\"bullet2\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "The key parts of the code in this notebook are:\n",
    "\n",
    " - Read the morpheus outputfile and split the raw output into entries (one per word).\n",
    " - Parse each entry and gather every morphological element (lemma, stem, ending, tense, voice, mood, person, case, gender, number, degree, dialect, variant, inflection class, etc.).  \n",
    " - Build a Python dict (`parsed_data`) mapping each input word to a list of parse dictionaries, then  dump it as nicely‑formatted JSON.\n",
    "\n",
    "The code is fully modular and heavily commented for maintainability and expantion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06180c88-a561-434e-97fe-67b915090d4b",
   "metadata": {},
   "source": [
    "## 2.1 - Read the morpheus outputfile\n",
    "\n",
    "This is part 1; it reads the morpheus outputfile and splits the raw output into entries (one per word). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac42c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import beta_code\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def read_morpheus_file(file_path):\n",
    "    \"\"\"\n",
    "    Read a Morpheus output text file and split it into entries (one per analysed word).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str or Path\n",
    "        Path to the Morpheus output file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[list[str]]\n",
    "        A list; each element is a list of lines (strings) belonging to one word entry.\n",
    "    \"\"\"\n",
    "    entries = []\n",
    "    current_entry = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as fh:\n",
    "        for line in fh:\n",
    "            if line.strip().startswith(\"-----\"):   # separator line\n",
    "                if current_entry:\n",
    "                    entries.append(current_entry)\n",
    "                current_entry = []\n",
    "            else:\n",
    "                current_entry.append(line.rstrip(\"\\n\"))\n",
    "    if current_entry:\n",
    "        entries.append(current_entry)\n",
    "    return entries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa0f3ca-fe4c-4990-9b08-62924f3cef99",
   "metadata": {},
   "source": [
    "## 2.2 - Parse each entry and gather morphological elements <a class=\"anchor\" id=\"bullet2x2\"></a>\n",
    "\n",
    "This is part 2 and it is the meat to the bone; the engine. Here we parse each entry and gather every morphological element (lemma, stem, ending, tense, voice, mood, person, case, gender, number, degree, dialect, variant, inflection class, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef8aeaa-5199-4dcd-9e67-e320c67d05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entry(entry_lines):\n",
    "    \"\"\"\n",
    "    Parse one word entry from Morpheus output and return (word, parses).\n",
    "\n",
    "    Parameters:\n",
    "        entry_lines : list[str]\n",
    "            Lines belonging to a single entry.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, list[dict]]\n",
    "            word_beta : The queried word in Beta Code.\n",
    "            parses    : List of dicts, each containing morphological data.\n",
    "    \"\"\"\n",
    "    if not entry_lines or not entry_lines[0].startswith(\"Word:\"):\n",
    "        return None\n",
    "\n",
    "    word_beta = entry_lines[0].split(\":\", 1)[1].strip()\n",
    "    for ln in entry_lines[1:]:\n",
    "        if ln.strip().startswith(\"Error:\"):\n",
    "            return word_beta, []\n",
    "\n",
    "    parses = []\n",
    "    current = None\n",
    "\n",
    "    for ln in entry_lines[1:]:\n",
    "        if not ln.strip():\n",
    "            continue\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # :raw  – obtain the raw form\n",
    "        # ---------------------------------------------------------------\n",
    "        if ln.startswith(\":raw\"):\n",
    "            if current is not None:\n",
    "                parses.append(current)\n",
    "            current = {}\n",
    "            continue\n",
    "\n",
    "        if current is None:\n",
    "            continue\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # :lem  – keep full lemma, split off numeric homonym, add Unicode\n",
    "        # ---------------------------------------------------------------\n",
    "        if ln.startswith(\":lem\"):\n",
    "            lemma_field = ln.split(\" \", 1)[1].strip()        # e.g.  le/gw1\n",
    "            current[\"lemma_beta\"] = lemma_field              # full form with suffix\n",
    "\n",
    "            # Separate base-lemma and numeric homonym tag (if any)\n",
    "            m = re.match(r\"^(.*?)(\\d+)$\", lemma_field)\n",
    "            if m:\n",
    "                current[\"lemma_base\"] = m.group(1)           # le/gw\n",
    "                current[\"homonym\"]    = int(m.group(2))      # 1\n",
    "            else:\n",
    "                current[\"lemma_base\"] = lemma_field          # no numeric suffix\n",
    "\n",
    "            # Unicode copies\n",
    "            current[\"lemma_unicode\"]       = beta_code.beta_code_to_greek(lemma_field)\n",
    "            current[\"lemma_base_unicode\"]  = beta_code.beta_code_to_greek(current[\"lemma_base\"])\n",
    "\n",
    "        elif ln.startswith(\":prvb\"):\n",
    "            pv = ln.partition(\" \")[2].strip()\n",
    "            if pv:\n",
    "                current[\"prefix\"] = pv\n",
    "\n",
    "        elif ln.startswith(\":aug1\"):\n",
    "            aug = ln.partition(\" \")[2].strip()\n",
    "            if aug:\n",
    "                current[\"augment\"] = aug\n",
    "\n",
    "        elif ln.startswith(\":stem\"):\n",
    "            content = ln.partition(\" \")[2].strip()\n",
    "            if content:\n",
    "                parts = content.split()\n",
    "                current[\"stem\"] = parts[0]\n",
    "                if len(parts) > 1:\n",
    "                    cls = parts[-1]\n",
    "                    if \"_\" in cls or \",\" in cls:\n",
    "                        codes = [c.strip() for c in cls.split(\",\") if c.strip()]\n",
    "                        current[\"inflection_class\"] = codes if len(codes) > 1 else codes[0]\n",
    "\n",
    "        elif ln.startswith(\":suff\"):\n",
    "            suff = ln.partition(\" \")[2].strip()\n",
    "            if suff:\n",
    "                current[\"suffix\"] = suff\n",
    "\n",
    "        elif ln.startswith(\":end\"):\n",
    "            content = ln.partition(\" \")[2].strip()\n",
    "            if not content:\n",
    "                continue\n",
    "\n",
    "            toks = content.split()\n",
    "            current[\"ending\"] = toks[0]\n",
    "            morph_toks = toks[1:]\n",
    "\n",
    "            # Split off trailing pattern codes (contain _ or ,)\n",
    "            pattern = []\n",
    "            for i, tok in enumerate(morph_toks):\n",
    "                if \"_\" in tok or \",\" in tok:\n",
    "                    pattern = morph_toks[i:]\n",
    "                    morph_toks = morph_toks[:i]\n",
    "                    break\n",
    "            if pattern:\n",
    "                codes = [c for tok in pattern for c in tok.split(\",\") if c]\n",
    "                if codes:\n",
    "                    if \"inflection_class\" in current:\n",
    "                        exist = current[\"inflection_class\"]\n",
    "                        if not isinstance(exist, list):\n",
    "                            exist = [exist]\n",
    "                        for c in codes:\n",
    "                            if c not in exist:\n",
    "                                exist.append(c)\n",
    "                        current[\"inflection_class\"] = exist if len(exist) > 1 else exist[0]\n",
    "                    else:\n",
    "                        current[\"inflection_class\"] = codes if len(codes) > 1 else codes[0]\n",
    "\n",
    "            VALID_CASE = {\"nom\",\"gen\",\"dat\",\"acc\",\"voc\"}\n",
    "            VALID_GEND = {\"masc\",\"fem\",\"neut\"}\n",
    "\n",
    "            cat = {}\n",
    "            for tok in morph_toks:\n",
    "                t = tok.lower()\n",
    "\n",
    "                # gender\n",
    "                if all(p in VALID_GEND for p in t.split(\"/\")):\n",
    "                    g = t.split(\"/\")\n",
    "                    cat[\"gender\"] = g if len(g) > 1 else g[0]\n",
    "                    continue\n",
    "                # case\n",
    "                if all(p in VALID_CASE for p in t.split(\"/\")):\n",
    "                    c = t.split(\"/\")\n",
    "                    cat[\"case\"] = c if len(c) > 1 else c[0]\n",
    "                    continue\n",
    "                # number\n",
    "                if t in {\"sg\",\"singular\",\"pl\",\"plural\"}:\n",
    "                    cat[\"number\"] = \"singular\" if t.startswith(\"s\") else \"plural\"\n",
    "                    continue\n",
    "                # tense\n",
    "                tense_map = {\"pres\":\"present\",\"present\":\"present\",\n",
    "                             \"imperf\":\"imperfect\",\"imperfect\":\"imperfect\",\n",
    "                             \"fut\":\"future\",\"future\":\"future\",\n",
    "                             \"aor\":\"aorist\",\"aorist\":\"aorist\",\n",
    "                             \"perf\":\"perfect\",\"perfect\":\"perfect\",\n",
    "                             \"plup\":\"pluperfect\",\"pluperfect\":\"pluperfect\"}\n",
    "                if t in tense_map:\n",
    "                    cat[\"tense\"] = tense_map[t]\n",
    "                    continue\n",
    "                # mood\n",
    "                mood_map = {\"ind\":\"indicative\",\"indicative\":\"indicative\",\n",
    "                            \"subj\":\"subjunctive\",\"subjunctive\":\"subjunctive\",\n",
    "                            \"opt\":\"optative\",\"optative\":\"optative\",\n",
    "                            \"imperat\":\"imperative\",\"imperative\":\"imperative\",\n",
    "                            \"inf\":\"infinitive\",\"infinitive\":\"infinitive\",\n",
    "                            \"part\":\"participle\",\"participle\":\"participle\"}\n",
    "                if t in mood_map:\n",
    "                    cat[\"mood\"] = mood_map[t]\n",
    "                    continue\n",
    "                # voice\n",
    "                voice_map = {\"act\":\"active\",\"active\":\"active\",\n",
    "                             \"mid\":\"middle\",\"middle\":\"middle\",\n",
    "                             \"pass\":\"passive\",\"passive\":\"passive\",\n",
    "                             \"mid/pass\":\"middle/passive\",\"mp\":\"middle/passive\",\n",
    "                             \"act/pass\":\"active/passive\"}\n",
    "                if t in voice_map:\n",
    "                    cat[\"voice\"] = voice_map[t]\n",
    "                    continue\n",
    "                # person\n",
    "                if t in {\"1st\",\"2nd\",\"3rd\"}:\n",
    "                    cat[\"person\"] = int(t[0])\n",
    "                    continue\n",
    "                # degree\n",
    "                if t in {\"comp\",\"comparative\"}:\n",
    "                    cat[\"degree\"] = \"comparative\"\n",
    "                    continue\n",
    "                if t in {\"superl\",\"superlative\"}:\n",
    "                    cat[\"degree\"] = \"superlative\"\n",
    "                    continue\n",
    "                # dialect or variant\n",
    "                dialects = {\"attic\",\"doric\",\"ionic\",\"aeolic\",\"epic\",\"poetic\"}\n",
    "                variants = {\"contr\",\"enclitic\",\"proclitic\",\"irreg\"}\n",
    "                if t in dialects:\n",
    "                    cat.setdefault(\"dialect\", []).append(t)\n",
    "                elif t in variants:\n",
    "                    cat.setdefault(\"variant\", []).append(t)\n",
    "                else:\n",
    "                    cat.setdefault(\"other\", []).append(tok)\n",
    "\n",
    "            current.update(cat)\n",
    "\n",
    "    if current is not None:\n",
    "        parses.append(current)\n",
    "    return word_beta, parses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72e3c8-8575-4eb9-8158-51646df4c078",
   "metadata": {},
   "source": [
    "## 2.3 - Run on a File & Export JSON <a class=\"anchor\" id=\"bullet2x3\"></a>\n",
    "\n",
    "This short function build a Python dict mapping each input word to a list of parse dictionaries, then dump it as nicely‑formatted JSON to a file (name provided at runtime).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd77fbb3-1352-474f-9361-bd515fd23e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morpheus_to_json(input_path: str | Path, output_path: str | Path | None = None):\n",
    "    \"\"\"Parse *input_path* and save JSON to *output_path* (or return dict).\"\"\"\n",
    "    entries = read_morpheus_file(input_path)\n",
    "    data = {}\n",
    "    for ent in entries:\n",
    "        res = parse_entry(ent)\n",
    "        if res:\n",
    "            word, parses = res\n",
    "            data[word] = parses\n",
    "\n",
    "    if output_path:\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as fh:\n",
    "            json.dump(data, fh, ensure_ascii=False, indent=2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c01ce6-ac74-433a-9155-daa35531351b",
   "metadata": {},
   "source": [
    "## 2.4 - Running the extraction <a class=\"anchor\" id=\"bullet2x4\"></a>\n",
    "\n",
    "The following lines of code execute the functions defined in the previous sections. Before execution it checks if the input file can be located. After analysis, the first few items are also dumped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f62fce-09b9-426f-8b25-96f439a2e577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing gnt_morphology_results.txt ...\n",
      "Saved JSON to gnt_morphology_results.json\n",
      "\n",
      "First two items in parsed JSON:\n",
      "{\n",
      "  \"agnwstw\": []\n",
      "}\n",
      "{\n",
      "  \"anaqema\": []\n",
      "}\n",
      "{\n",
      "  \"ai)gupti/wn\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "input_file = Path(\"gnt_morphology_results.txt\")\n",
    "output_file = Path(\"gnt_morphology_results.json\")\n",
    "\n",
    "if input_file.exists():\n",
    "    print(f\"Parsing {input_file} ...\")\n",
    "    parsed = morpheus_to_json(input_file, output_file)\n",
    "    print(f\"Saved JSON to {output_file}\\n\")\n",
    "\n",
    "    # Print the first two items for a quick sanity check\n",
    "    first_two = list(parsed.items())[:3]\n",
    "    print(\"First two items in parsed JSON:\")\n",
    "    for word, parses in first_two:\n",
    "        print(json.dumps({word: parses}, ensure_ascii=False, indent=2))\n",
    "else:\n",
    "    print(\n",
    "        f\"Input file '{input_file}' not found.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2127dc7-4ae8-4b0a-8803-e4214864b731",
   "metadata": {},
   "source": [
    "# 3 - Acknowledgements <a class=\"anchor\" id=\"bullet3\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "This Jupyter notebook used the following sources for the analysis and implementation:\n",
    "\n",
    "- [Morpheus Morphological Analyzer (Perseus Project)](https://github.com/perseids-tools/morpheus/)\n",
    "- [Greek Beta Code standard](https://stephanus.tlg.uci.edu/encoding/BCM.pdf)\n",
    "- [beta-code-py](https://github.com/perseids-tools/beta-code-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6464b45-d97e-4180-8c62-e3d436caf473",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4 - Required libraries <a class=\"anchor\" id=\"bullet4\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "The scripts in this notebook require Python 3.8+ and the following libraries to be installed in the environment:\n",
    "\n",
    "``` python\n",
    "    beta_code\n",
    "    json\n",
    "    pathlib\n",
    "```\n",
    "\n",
    "You can install any missing library from within Jupyter Notebook using either `pip` or `pip3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab924eee-b524-42f0-a0b8-edd06158eb48",
   "metadata": {},
   "source": [
    "# 5 - Notebook version details<a class=\"anchor\" id=\"bullet5\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "<div style=\"float: left;\">\n",
    "  <table>\n",
    "    <tr>\n",
    "      <td><strong>Author</strong></td>\n",
    "      <td>Tony Jurg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Version</strong></td>\n",
    "      <td>1.2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Date</strong></td>\n",
    "      <td>30 April 2025</td>\n",
    "    </tr>\n",
    "  </table>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
