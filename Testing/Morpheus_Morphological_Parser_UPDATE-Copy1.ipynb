{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91841c64",
   "metadata": {},
   "source": [
    "# Morpheus Morphological Parser (versie 16 mei)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ddd23-b7f4-4137-8e7b-2f32115c4bf1",
   "metadata": {},
   "source": [
    "## Table of content (ToC)<a class=\"anchor\" id=\"TOC\"></a>\n",
    "* <a href=\"#bullet1\">1 - Introduction</a>\n",
    "    * <a href=\"#bullet1x1\">1.1 - Production environment</a>\n",
    "    * <a href=\"#bullet1x2\">1.2 - Test environment</a>\n",
    "* <a href=\"#bullet2\">2 - Setting up</a>\n",
    "    * <a href=\"#bullet2x1\">2.1 - Determine the main classes of Part of Speech</a>\n",
    "    * <a href=\"#bullet2x2\">2.2 - Determine the SP morphological tag</a>\n",
    "    * <a href=\"#bullet2x3\">2.3 - Gather details from Morpheus blocks</a>\n",
    "    * <a href=\"#bullet2x4\">2.4 - Analyzing a single word</a>\n",
    "* <a href=\"#bullet3\">3 - Production</a>\n",
    "    * <a href=\"#bullet3x1\">3.1 - Load the input words</a>\n",
    "    * <a href=\"#bullet3x2\">3.2 - Running the production</a>\n",
    "* <a href=\"#bullet4\">4 - Validation</a>\n",
    "    * <a href=\"#bullet4x1\">4.1 - Load the test files</a>\n",
    "    * <a href=\"#bullet4x2\">4.2 - Run the test files</a>\n",
    "* <a href=\"#bullet5\">5 - Atribution and footnotes</a>\n",
    "* <a href=\"#bullet6\">6 - Required libraries</a>\n",
    "* <a href=\"#bullet7\">7 - Notebook version</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968fa1e-0d2a-4cae-91ad-1edf7787d108",
   "metadata": {},
   "source": [
    "# 1 - Introduction <a class=\"anchor\" id=\"bullet1\"></a>\n",
    "##### [Back to ToC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7f52f-930b-4b1d-9136-931cb09087b4",
   "metadata": {},
   "source": [
    "The parsing process is distributed over a few cells in this notebook. The actual start of the analysis starts in section [bla], but all prior cells need to be executed before. When in cell [b;a], the analysis begins with a simple Betacode string (the Greek word rendered in ASCII) which were read from a plain text file (in step []).\n",
    "\n",
    "Each word is then passed off to the `analyze_word_with_morpheus` function. That function is responsible for encoding the word into a URL-safe form, sending an HTTP request to the local Morpheus server running in its virtualized container. From this we retrieve the raw, line‐oriented output. As soon as the response arrives, it is split on every line that begins with `:raw`, producing discrete “blocks” of analysis, each of which corresponds to one of parses by Morpheus.\n",
    "\n",
    "Each block is then fed into `parse_word_block` which walks through all of the output lines. It will looking labels like `:lem`, `:stem`, and `:end`. From this it assembles a rich dictionary of morphological features for every possible parse. Once those raw features are in place, two post‐processing routines are called. First, `analyze_pos` examines the feature dictionary to assign a part of speech label. For this it will check for keywords, indeclinable forms (turning neuter‐singular indeclinables into adverbs and the rest into particles), verbal markers like tense or mood, and a host of other morph‐code clues. Next, `analyze_morph_tag` constructs the standardized Robinson/Pierpont tag. It builds upon the previous POS analysis and add to the prefix items like tense, voice, mood, person and number (for verbs) or case/number/gender/degree (for nouns and adjectives). The function then returns a very compact code like `V‐PAP‐DSM` or `A‐NSM`.\n",
    "\n",
    "## 1.1 - Production <a class=\"anchor\" id=\"bullet1x1\"></a>\n",
    "\n",
    "Production!\n",
    "\n",
    "## 1.2 - Test <a class=\"anchor\" id=\"bullet1x2\"></a>\n",
    "\n",
    "Beside a production type of section, there is also a test section. In this section I load a tab-separated file of word-and-expected-tag pairs. This will be used by `funct` to call `analyze_word_with_morpheus` for each word found in the test set. From the results of this function, it gathers the  multi‐tag strings (which are SP tags joined by “/”). This string is then flattened in a simple deduplicated list using function `flatten_tags`. This allows to easily checks whether the expected tag (which was taken from N1904-TF) appears in that list. A counter is updated recording the amount of match/no-match. Since there is a significant difference in word clasification between SP and Morpheus, a 'no-match' does not always indicate a fail. A small HTML‐generation routine stitches together the raw Morpheus blocks (formatted by `format_string`) and the escaped JSON of parsed dictionaries. Colours are added to visualize the match/no-match results. The final product of the test is a standalone HTML report that shows for every input word exactly what Morpheus returned, how it was parsed and tagged, and whether it matched with the SP tag found in N1904-TF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762480bd-194f-405c-9578-7c982e89ede9",
   "metadata": {},
   "source": [
    "# 2 - Setting up <a class=\"anchor\" id=\"bullet2\"></a>\n",
    "##### [Back to ToC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf7d0c-69d4-4d5d-801c-676b062121ac",
   "metadata": {},
   "source": [
    "## 2.1 - Load the morphkit library <a class=\"anchor\" id=\"bullet2x1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c845df43-869c-4358-80d8-a931f7f571d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d30dd1-6947-490a-826c-7b1ccb92108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morphkit loaded\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../morphkit\")    # relative to notebook dir\n",
    "import morphkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfceb077-c0c2-4ada-ad9a-46a5bf4e5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Analyze a word with Morpheus\n",
    "result=morphkit.analyze_word_with_morpheus('th\\\\n', 'http://10.0.1.156:1315/greek/',debug=False)\n",
    "# result['analyses'] is a list of parse dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8832730e-6d80-4aa0-9728-e8f9c5776b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_label=article\n",
      "sp_tag=T-ASF\n",
      "decoded={'Part of Speech': 'Article', 'Case': 'Accusative', 'Number': 'Singular', 'Gender': 'Feminine'}\n"
     ]
    }
   ],
   "source": [
    "# 2. Inspect part of speech and SP tag for each analysis\n",
    "for parse in result['analyses']:\n",
    "    pos_label = morphkit.analyze_pos(parse)\n",
    "    print (f'pos_label={pos_label}')\n",
    "    sp_tag    = morphkit.analyze_morph_tag(parse)\n",
    "    print(f'sp_tag={sp_tag}')  # WARNING: this is a compound???\n",
    "    decoded   = morphkit.decode_tag(sp_tag)\n",
    "    print(f'decoded={decoded}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982aa11b-5c33-4561-b60d-dbc040470cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[compare_tags] First tag: N-NSN-ATT;  second tag: N-ASM-ATT\n",
      "[compare_tags] Part of Speech   : Noun         vs Noun         → sim=1.00, weight=10\n",
      "[compare_tags] Number           : Singular     vs Singular     → sim=1.00, weight=3\n",
      "[compare_tags] Tense            :              vs              → sim=1.00, weight=8\n",
      "[compare_tags] Voice            :              vs              → sim=1.00, weight=6\n",
      "[compare_tags] Mood             :              vs              → sim=1.00, weight=6\n",
      "[compare_tags] Gender           : Neuter       vs Masculine    → sim=0.20, weight=2\n",
      "[compare_tags] Case             : Nominative   vs Accusative   → sim=0.20, weight=4\n",
      "[compare_tags] Person           :              vs              → sim=1.00, weight=3\n",
      "[compare_tags] Suffix           : Attic        vs Attic        → sim=1.00, weight=1\n",
      "[compare_tags]  Overall similarity: 0.888\n",
      "\n",
      "score={'tag1': 'N-NSN-ATT', 'tag2': 'N-ASM-ATT', 'overall_similarity': 0.8883720930232557, 'details': {'Part of Speech': {'tag1': 'Noun', 'tag2': 'Noun', 'similarity': 1.0, 'weight': 10}, 'Number': {'tag1': 'Singular', 'tag2': 'Singular', 'similarity': 1.0, 'weight': 3}, 'Tense': {'tag1': '', 'tag2': '', 'similarity': 1.0, 'weight': 8}, 'Voice': {'tag1': '', 'tag2': '', 'similarity': 1.0, 'weight': 6}, 'Mood': {'tag1': '', 'tag2': '', 'similarity': 1.0, 'weight': 6}, 'Gender': {'tag1': 'Neuter', 'tag2': 'Masculine', 'similarity': 0.2, 'weight': 2}, 'Case': {'tag1': 'Nominative', 'tag2': 'Accusative', 'similarity': 0.2, 'weight': 4}, 'Person': {'tag1': '', 'tag2': '', 'similarity': 1.0, 'weight': 3}, 'Suffix': {'tag1': 'Attic', 'tag2': 'Attic', 'similarity': 1.0, 'weight': 1}}}\n",
      "\n",
      "Similarity: 0.8883720930232557\n"
     ]
    }
   ],
   "source": [
    "# 3. Compare two SP tags\n",
    "score = morphkit.compare_tags('N-NSN-ATT', 'N-ASM-ATT', debug=True)\n",
    "print (f'\\nscore={score}')\n",
    "print(f\"\\nSimilarity: {score['overall_similarity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c997ce-a8ed-4d32-b6fe-bad187dc05eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag1': 'N-NSN-ATT',\n",
       " 'tag2': 'N-ASM-ATT',\n",
       " 'overall_similarity': 0.8883720930232557,\n",
       " 'details': {'Part of Speech': {'tag1': 'Noun',\n",
       "   'tag2': 'Noun',\n",
       "   'similarity': 1.0,\n",
       "   'weight': 10},\n",
       "  'Number': {'tag1': 'Singular',\n",
       "   'tag2': 'Singular',\n",
       "   'similarity': 1.0,\n",
       "   'weight': 3},\n",
       "  'Tense': {'tag1': '', 'tag2': '', 'similarity': 1.0, 'weight': 8},\n",
       "  'Voice': {'tag1': '', 'tag2': '', 'similarity': 1.0, 'weight': 6},\n",
       "  'Mood': {'tag1': '', 'tag2': '', 'similarity': 1.0, 'weight': 6},\n",
       "  'Gender': {'tag1': 'Neuter',\n",
       "   'tag2': 'Masculine',\n",
       "   'similarity': 0.2,\n",
       "   'weight': 2},\n",
       "  'Case': {'tag1': 'Nominative',\n",
       "   'tag2': 'Accusative',\n",
       "   'similarity': 0.2,\n",
       "   'weight': 4},\n",
       "  'Person': {'tag1': '', 'tag2': '', 'similarity': 1.0, 'weight': 3},\n",
       "  'Suffix': {'tag1': 'Attic',\n",
       "   'tag2': 'Attic',\n",
       "   'similarity': 1.0,\n",
       "   'weight': 1}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morphkit.compare_tags(\"N-NSN-ATT\", \"N-ASM-ATT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c99bf92-0369-453f-a320-630c233ff04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[decode_tag] Return ({'Part of Speech': 'Verb', 'Tense': 'Imperfect', 'Voice': 'Active', 'Mood': 'Indicative', 'Person': 'First Person', 'Number': 'Singular', 'Suffix': 'ERROR: Unknown suffix -CF'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Part of Speech': 'Verb',\n",
       " 'Tense': 'Imperfect',\n",
       " 'Voice': 'Active',\n",
       " 'Mood': 'Indicative',\n",
       " 'Person': 'First Person',\n",
       " 'Number': 'Singular',\n",
       " 'Suffix': 'ERROR: Unknown suffix -CF'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morphkit.decode_tag(\"V-IAI-1S-CF\",debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "583ff5b5-38ac-414c-8564-627d1d5fe77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[decode_tag] Return ({'Part of Speech': 'Noun', 'Case': 'Accusative', 'Number': 'Singular', 'Gender': 'Feminine', 'Suffix': 'Comparative'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Part of Speech': 'Noun',\n",
       " 'Case': 'Accusative',\n",
       " 'Number': 'Singular',\n",
       " 'Gender': 'Feminine',\n",
       " 'Suffix': 'Comparative'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morphkit.decode_tag(\"N-ASF-C\",debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f7751d5-3c9b-4c77-8bb5-7437b4660eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'e)/sxaton',\n",
       " 'raw_text': '\\n:raw e)/sxaton\\n\\n:workw e)/sxaton\\n:lem e)/sxatos\\n:prvb \\t\\t\\t\\t\\n:aug1 \\t\\t\\t\\t\\n:stem e)sxat\\t\\t\\t\\tos_h_on\\n:suff \\t\\t\\t\\t\\n:end on\\t masc acc sg\\t\\t\\tos_h_on\\n\\n:raw e)/sxaton\\n\\n:workw e)/sxaton\\n:lem e)/sxatos\\n:prvb \\t\\t\\t\\t\\n:aug1 \\t\\t\\t\\t\\n:stem e)sxat\\t\\t\\t\\tos_h_on\\n:suff \\t\\t\\t\\t\\n:end on\\t neut nom/voc/acc sg\\t\\t\\tos_h_on\\n\\n:raw e)/sxaton\\n\\n:workw e)sxa=ton\\n:lem ei)s-xa/w\\n:prvb ei)s\\t\\t\\tshort_eis\\t\\n:aug1 \\t\\t\\t\\t\\n:stem x\\t\\t\\t\\taw_pr,aw_denom\\n:suff \\t\\t\\t\\t\\n:end a=ton\\t pres imperat act 2nd dual\\t\\tcontr\\taw_pr\\n\\n:raw e)/sxaton\\n\\n:workw e)sxa=ton\\n:lem ei)s-xa/w\\n:prvb ei)s\\t\\t\\tshort_eis\\t\\n:aug1 \\t\\t\\t\\t\\n:stem x\\t\\t\\t\\taw_pr,aw_denom\\n:suff \\t\\t\\t\\t\\n:end a=ton\\t pres subj act 3rd dual\\t\\tcontr\\taw_pr\\n\\n:raw e)/sxaton\\n\\n:workw e)sxa=ton\\n:lem ei)s-xa/w\\n:prvb ei)s\\t\\t\\tshort_eis\\t\\n:aug1 \\t\\t\\t\\t\\n:stem x\\t\\t\\t\\taw_pr,aw_denom\\n:suff \\t\\t\\t\\t\\n:end a=ton\\t pres subj act 2nd dual\\t\\tcontr\\taw_pr\\n\\n:raw e)/sxaton\\n\\n:workw e)sxa=ton\\n:lem ei)s-xa/w\\n:prvb ei)s\\t\\t\\tshort_eis\\t\\n:aug1 \\t\\t\\t\\t\\n:stem x\\t\\t\\t\\taw_pr,aw_denom\\n:suff \\t\\t\\t\\t\\n:end a=ton\\t pres ind act 3rd dual\\t\\tcontr\\taw_pr\\n\\n:raw e)/sxaton\\n\\n:workw e)sxa=ton\\n:lem ei)s-xa/w\\n:prvb ei)s\\t\\t\\tshort_eis\\t\\n:aug1 \\t\\t\\t\\t\\n:stem x\\t\\t\\t\\taw_pr,aw_denom\\n:suff \\t\\t\\t\\t\\n:end a=ton\\t pres ind act 2nd dual\\t\\tcontr\\taw_pr\\n\\n:raw e)/sxaton\\n\\n:workw e)sxa=ton\\n:lem ei)s-xa/w\\n:prvb ei)s\\t\\t\\tshort_eis\\t\\n:aug1 \\t\\t\\t\\t\\n:stem x\\t\\t\\tunaugmented\\taw_pr,aw_denom\\n:suff \\t\\t\\t\\t\\n:end a=ton\\t imperf ind act 2nd dual\\t\\tcontr\\taw_pr\\n\\n:raw e)/sxaton\\n\\n:workw e)sxa=ton\\n:lem sxa/w\\n:prvb \\t\\t\\t\\t\\n:aug1 e)\\t\\t\\t\\t\\n:stem sx\\t ind\\t\\t\\taw_pr,aw_denom\\n:suff \\t\\t\\t\\t\\n:end a=ton\\t imperf ind act 2nd dual\\t\\tcontr\\taw_pr\\n\\n:raw e)/sxaton\\n\\n:workw e)sxa=ton\\n:lem sxa/zw\\n:prvb \\t\\t\\t\\t\\n:aug1 e)\\t\\t\\t\\t\\n:stem sx\\t ind\\t\\t\\taw_pr,a_stem\\n:suff \\t\\t\\t\\t\\n:end a=ton\\t imperf ind act 2nd dual\\t\\tcontr\\taw_pr\\n',\n",
       " 'blocks': [[':raw e)/sxaton',\n",
       "   '',\n",
       "   ':workw e)/sxaton',\n",
       "   ':lem e)/sxatos',\n",
       "   ':prvb \\t\\t\\t\\t',\n",
       "   ':aug1 \\t\\t\\t\\t',\n",
       "   ':stem e)sxat\\t\\t\\t\\tos_h_on',\n",
       "   ':suff \\t\\t\\t\\t',\n",
       "   ':end on\\t masc acc sg\\t\\t\\tos_h_on',\n",
       "   ''],\n",
       "  [':raw e)/sxaton',\n",
       "   '',\n",
       "   ':workw e)/sxaton',\n",
       "   ':lem e)/sxatos',\n",
       "   ':prvb \\t\\t\\t\\t',\n",
       "   ':aug1 \\t\\t\\t\\t',\n",
       "   ':stem e)sxat\\t\\t\\t\\tos_h_on',\n",
       "   ':suff \\t\\t\\t\\t',\n",
       "   ':end on\\t neut nom/voc/acc sg\\t\\t\\tos_h_on',\n",
       "   ''],\n",
       "  [':raw e)/sxaton',\n",
       "   '',\n",
       "   ':workw e)sxa=ton',\n",
       "   ':lem ei)s-xa/w',\n",
       "   ':prvb ei)s\\t\\t\\tshort_eis\\t',\n",
       "   ':aug1 \\t\\t\\t\\t',\n",
       "   ':stem x\\t\\t\\t\\taw_pr,aw_denom',\n",
       "   ':suff \\t\\t\\t\\t',\n",
       "   ':end a=ton\\t pres imperat act 2nd dual\\t\\tcontr\\taw_pr',\n",
       "   ''],\n",
       "  [':raw e)/sxaton',\n",
       "   '',\n",
       "   ':workw e)sxa=ton',\n",
       "   ':lem ei)s-xa/w',\n",
       "   ':prvb ei)s\\t\\t\\tshort_eis\\t',\n",
       "   ':aug1 \\t\\t\\t\\t',\n",
       "   ':stem x\\t\\t\\t\\taw_pr,aw_denom',\n",
       "   ':suff \\t\\t\\t\\t',\n",
       "   ':end a=ton\\t pres subj act 3rd dual\\t\\tcontr\\taw_pr',\n",
       "   ''],\n",
       "  [':raw e)/sxaton',\n",
       "   '',\n",
       "   ':workw e)sxa=ton',\n",
       "   ':lem ei)s-xa/w',\n",
       "   ':prvb ei)s\\t\\t\\tshort_eis\\t',\n",
       "   ':aug1 \\t\\t\\t\\t',\n",
       "   ':stem x\\t\\t\\t\\taw_pr,aw_denom',\n",
       "   ':suff \\t\\t\\t\\t',\n",
       "   ':end a=ton\\t pres subj act 2nd dual\\t\\tcontr\\taw_pr',\n",
       "   ''],\n",
       "  [':raw e)/sxaton',\n",
       "   '',\n",
       "   ':workw e)sxa=ton',\n",
       "   ':lem ei)s-xa/w',\n",
       "   ':prvb ei)s\\t\\t\\tshort_eis\\t',\n",
       "   ':aug1 \\t\\t\\t\\t',\n",
       "   ':stem x\\t\\t\\t\\taw_pr,aw_denom',\n",
       "   ':suff \\t\\t\\t\\t',\n",
       "   ':end a=ton\\t pres ind act 3rd dual\\t\\tcontr\\taw_pr',\n",
       "   ''],\n",
       "  [':raw e)/sxaton',\n",
       "   '',\n",
       "   ':workw e)sxa=ton',\n",
       "   ':lem ei)s-xa/w',\n",
       "   ':prvb ei)s\\t\\t\\tshort_eis\\t',\n",
       "   ':aug1 \\t\\t\\t\\t',\n",
       "   ':stem x\\t\\t\\t\\taw_pr,aw_denom',\n",
       "   ':suff \\t\\t\\t\\t',\n",
       "   ':end a=ton\\t pres ind act 2nd dual\\t\\tcontr\\taw_pr',\n",
       "   ''],\n",
       "  [':raw e)/sxaton',\n",
       "   '',\n",
       "   ':workw e)sxa=ton',\n",
       "   ':lem ei)s-xa/w',\n",
       "   ':prvb ei)s\\t\\t\\tshort_eis\\t',\n",
       "   ':aug1 \\t\\t\\t\\t',\n",
       "   ':stem x\\t\\t\\tunaugmented\\taw_pr,aw_denom',\n",
       "   ':suff \\t\\t\\t\\t',\n",
       "   ':end a=ton\\t imperf ind act 2nd dual\\t\\tcontr\\taw_pr',\n",
       "   ''],\n",
       "  [':raw e)/sxaton',\n",
       "   '',\n",
       "   ':workw e)sxa=ton',\n",
       "   ':lem sxa/w',\n",
       "   ':prvb \\t\\t\\t\\t',\n",
       "   ':aug1 e)\\t\\t\\t\\t',\n",
       "   ':stem sx\\t ind\\t\\t\\taw_pr,aw_denom',\n",
       "   ':suff \\t\\t\\t\\t',\n",
       "   ':end a=ton\\t imperf ind act 2nd dual\\t\\tcontr\\taw_pr',\n",
       "   ''],\n",
       "  [':raw e)/sxaton',\n",
       "   '',\n",
       "   ':workw e)sxa=ton',\n",
       "   ':lem sxa/zw',\n",
       "   ':prvb \\t\\t\\t\\t',\n",
       "   ':aug1 e)\\t\\t\\t\\t',\n",
       "   ':stem sx\\t ind\\t\\t\\taw_pr,a_stem',\n",
       "   ':suff \\t\\t\\t\\t',\n",
       "   ':end a=ton\\t imperf ind act 2nd dual\\t\\tcontr\\taw_pr']],\n",
       " 'analyses': [{'raw_beta': 'e)/sxaton',\n",
       "   'raw_unicode': 'ἔσχατον',\n",
       "   'work_beta': 'e)/sxaton',\n",
       "   'work_unicode': 'ἔσχατον',\n",
       "   'lemma_beta': 'e)/sxatos',\n",
       "   'lemma_base': 'e)/sxatos',\n",
       "   'lemma_unicode': 'ἔσχατος',\n",
       "   'lemma_base_unicode': 'ἔσχατος',\n",
       "   'stem_beta': 'e)sxat',\n",
       "   'stem_unicode': 'ἐσχατ',\n",
       "   'morph_codes': ['os_h_on', 'os_h_on'],\n",
       "   'ending_beta': 'on',\n",
       "   'ending_unicode': 'ον',\n",
       "   'gender': 'masc',\n",
       "   'case': 'acc',\n",
       "   'number': 'sg',\n",
       "   'pos': 'noun',\n",
       "   'sp_morph_tag': 'N-ASM'},\n",
       "  {'raw_beta': 'e)/sxaton',\n",
       "   'raw_unicode': 'ἔσχατον',\n",
       "   'work_beta': 'e)/sxaton',\n",
       "   'work_unicode': 'ἔσχατον',\n",
       "   'lemma_beta': 'e)/sxatos',\n",
       "   'lemma_base': 'e)/sxatos',\n",
       "   'lemma_unicode': 'ἔσχατος',\n",
       "   'lemma_base_unicode': 'ἔσχατος',\n",
       "   'stem_beta': 'e)sxat',\n",
       "   'stem_unicode': 'ἐσχατ',\n",
       "   'morph_codes': ['os_h_on', 'os_h_on'],\n",
       "   'ending_beta': 'on',\n",
       "   'ending_unicode': 'ον',\n",
       "   'gender': 'neut',\n",
       "   'case': ['nom', 'voc', 'acc'],\n",
       "   'number': 'sg',\n",
       "   'pos': 'noun',\n",
       "   'sp_morph_tag': 'N-NSN/N-VSN/N-ASN'},\n",
       "  {'raw_beta': 'e)/sxaton',\n",
       "   'raw_unicode': 'ἔσχατον',\n",
       "   'work_beta': 'e)sxa=ton',\n",
       "   'work_unicode': 'ἐσχᾶτον',\n",
       "   'lemma_beta': 'ei)s-xa/w',\n",
       "   'lemma_base': 'ei)s-xa/w',\n",
       "   'lemma_unicode': 'εἰσ-χάω',\n",
       "   'lemma_base_unicode': 'εἰσ-χάω',\n",
       "   'preverb_beta': ['ei)s'],\n",
       "   'morph_flags': ['short_eis', 'contr'],\n",
       "   'stem_beta': 'x',\n",
       "   'stem_unicode': 'χ',\n",
       "   'morph_codes': ['aw_pr', 'aw_denom', 'aw_pr'],\n",
       "   'ending_beta': 'a=ton',\n",
       "   'ending_unicode': 'ᾶτον',\n",
       "   'tense': 'present',\n",
       "   'mood': 'imperative',\n",
       "   'voice': 'active',\n",
       "   'number': 'dual',\n",
       "   'person': '2',\n",
       "   'pos': 'verb',\n",
       "   'sp_morph_tag': 'V-PAM-2D'},\n",
       "  {'raw_beta': 'e)/sxaton',\n",
       "   'raw_unicode': 'ἔσχατον',\n",
       "   'work_beta': 'e)sxa=ton',\n",
       "   'work_unicode': 'ἐσχᾶτον',\n",
       "   'lemma_beta': 'ei)s-xa/w',\n",
       "   'lemma_base': 'ei)s-xa/w',\n",
       "   'lemma_unicode': 'εἰσ-χάω',\n",
       "   'lemma_base_unicode': 'εἰσ-χάω',\n",
       "   'preverb_beta': ['ei)s'],\n",
       "   'morph_flags': ['short_eis', 'contr'],\n",
       "   'stem_beta': 'x',\n",
       "   'stem_unicode': 'χ',\n",
       "   'morph_codes': ['aw_pr', 'aw_denom', 'aw_pr'],\n",
       "   'ending_beta': 'a=ton',\n",
       "   'ending_unicode': 'ᾶτον',\n",
       "   'tense': 'present',\n",
       "   'mood': 'subjunctive',\n",
       "   'voice': 'active',\n",
       "   'number': 'dual',\n",
       "   'person': '3',\n",
       "   'pos': 'verb',\n",
       "   'sp_morph_tag': 'V-PAS-3D'},\n",
       "  {'raw_beta': 'e)/sxaton',\n",
       "   'raw_unicode': 'ἔσχατον',\n",
       "   'work_beta': 'e)sxa=ton',\n",
       "   'work_unicode': 'ἐσχᾶτον',\n",
       "   'lemma_beta': 'ei)s-xa/w',\n",
       "   'lemma_base': 'ei)s-xa/w',\n",
       "   'lemma_unicode': 'εἰσ-χάω',\n",
       "   'lemma_base_unicode': 'εἰσ-χάω',\n",
       "   'preverb_beta': ['ei)s'],\n",
       "   'morph_flags': ['short_eis', 'contr'],\n",
       "   'stem_beta': 'x',\n",
       "   'stem_unicode': 'χ',\n",
       "   'morph_codes': ['aw_pr', 'aw_denom', 'aw_pr'],\n",
       "   'ending_beta': 'a=ton',\n",
       "   'ending_unicode': 'ᾶτον',\n",
       "   'tense': 'present',\n",
       "   'mood': 'subjunctive',\n",
       "   'voice': 'active',\n",
       "   'number': 'dual',\n",
       "   'person': '2',\n",
       "   'pos': 'verb',\n",
       "   'sp_morph_tag': 'V-PAS-2D'},\n",
       "  {'raw_beta': 'e)/sxaton',\n",
       "   'raw_unicode': 'ἔσχατον',\n",
       "   'work_beta': 'e)sxa=ton',\n",
       "   'work_unicode': 'ἐσχᾶτον',\n",
       "   'lemma_beta': 'ei)s-xa/w',\n",
       "   'lemma_base': 'ei)s-xa/w',\n",
       "   'lemma_unicode': 'εἰσ-χάω',\n",
       "   'lemma_base_unicode': 'εἰσ-χάω',\n",
       "   'preverb_beta': ['ei)s'],\n",
       "   'morph_flags': ['short_eis', 'contr'],\n",
       "   'stem_beta': 'x',\n",
       "   'stem_unicode': 'χ',\n",
       "   'morph_codes': ['aw_pr', 'aw_denom', 'aw_pr'],\n",
       "   'ending_beta': 'a=ton',\n",
       "   'ending_unicode': 'ᾶτον',\n",
       "   'tense': 'present',\n",
       "   'mood': 'indicative',\n",
       "   'voice': 'active',\n",
       "   'number': 'dual',\n",
       "   'person': '3',\n",
       "   'pos': 'verb',\n",
       "   'sp_morph_tag': 'V-PAI-3D'},\n",
       "  {'raw_beta': 'e)/sxaton',\n",
       "   'raw_unicode': 'ἔσχατον',\n",
       "   'work_beta': 'e)sxa=ton',\n",
       "   'work_unicode': 'ἐσχᾶτον',\n",
       "   'lemma_beta': 'ei)s-xa/w',\n",
       "   'lemma_base': 'ei)s-xa/w',\n",
       "   'lemma_unicode': 'εἰσ-χάω',\n",
       "   'lemma_base_unicode': 'εἰσ-χάω',\n",
       "   'preverb_beta': ['ei)s'],\n",
       "   'morph_flags': ['short_eis', 'contr'],\n",
       "   'stem_beta': 'x',\n",
       "   'stem_unicode': 'χ',\n",
       "   'morph_codes': ['aw_pr', 'aw_denom', 'aw_pr'],\n",
       "   'ending_beta': 'a=ton',\n",
       "   'ending_unicode': 'ᾶτον',\n",
       "   'tense': 'present',\n",
       "   'mood': 'indicative',\n",
       "   'voice': 'active',\n",
       "   'number': 'dual',\n",
       "   'person': '2',\n",
       "   'pos': 'verb',\n",
       "   'sp_morph_tag': 'V-PAI-2D'},\n",
       "  {'raw_beta': 'e)/sxaton',\n",
       "   'raw_unicode': 'ἔσχατον',\n",
       "   'work_beta': 'e)sxa=ton',\n",
       "   'work_unicode': 'ἐσχᾶτον',\n",
       "   'lemma_beta': 'ei)s-xa/w',\n",
       "   'lemma_base': 'ei)s-xa/w',\n",
       "   'lemma_unicode': 'εἰσ-χάω',\n",
       "   'lemma_base_unicode': 'εἰσ-χάω',\n",
       "   'preverb_beta': ['ei)s'],\n",
       "   'morph_flags': ['short_eis', 'unaugmented', 'contr'],\n",
       "   'stem_beta': 'x',\n",
       "   'stem_unicode': 'χ',\n",
       "   'morph_codes': ['aw_pr', 'aw_denom', 'aw_pr'],\n",
       "   'ending_beta': 'a=ton',\n",
       "   'ending_unicode': 'ᾶτον',\n",
       "   'tense': 'imperfect',\n",
       "   'mood': 'indicative',\n",
       "   'voice': 'active',\n",
       "   'number': 'dual',\n",
       "   'person': '2',\n",
       "   'pos': 'verb',\n",
       "   'sp_morph_tag': 'V-IAI-2D'},\n",
       "  {'raw_beta': 'e)/sxaton',\n",
       "   'raw_unicode': 'ἔσχατον',\n",
       "   'work_beta': 'e)sxa=ton',\n",
       "   'work_unicode': 'ἐσχᾶτον',\n",
       "   'lemma_beta': 'sxa/w',\n",
       "   'lemma_base': 'sxa/w',\n",
       "   'lemma_unicode': 'σχάω',\n",
       "   'lemma_base_unicode': 'σχάω',\n",
       "   'augment_beta': 'e)',\n",
       "   'stem_beta': 'sx',\n",
       "   'stem_unicode': 'σχ',\n",
       "   'morph_flags': ['ind', 'contr'],\n",
       "   'morph_codes': ['aw_pr', 'aw_denom', 'aw_pr'],\n",
       "   'ending_beta': 'a=ton',\n",
       "   'ending_unicode': 'ᾶτον',\n",
       "   'tense': 'imperfect',\n",
       "   'mood': 'indicative',\n",
       "   'voice': 'active',\n",
       "   'number': 'dual',\n",
       "   'person': '2',\n",
       "   'pos': 'verb',\n",
       "   'sp_morph_tag': 'V-IAI-2D'},\n",
       "  {'raw_beta': 'e)/sxaton',\n",
       "   'raw_unicode': 'ἔσχατον',\n",
       "   'work_beta': 'e)sxa=ton',\n",
       "   'work_unicode': 'ἐσχᾶτον',\n",
       "   'lemma_beta': 'sxa/zw',\n",
       "   'lemma_base': 'sxa/zw',\n",
       "   'lemma_unicode': 'σχάζω',\n",
       "   'lemma_base_unicode': 'σχάζω',\n",
       "   'augment_beta': 'e)',\n",
       "   'stem_beta': 'sx',\n",
       "   'stem_unicode': 'σχ',\n",
       "   'morph_flags': ['ind', 'contr'],\n",
       "   'morph_codes': ['aw_pr', 'a_stem', 'aw_pr'],\n",
       "   'ending_beta': 'a=ton',\n",
       "   'ending_unicode': 'ᾶτον',\n",
       "   'tense': 'imperfect',\n",
       "   'mood': 'indicative',\n",
       "   'voice': 'active',\n",
       "   'number': 'dual',\n",
       "   'person': '2',\n",
       "   'pos': 'verb',\n",
       "   'sp_morph_tag': 'V-IAI-2D'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseUrl=\"http://10.0.1.156:1315/greek/\" # (IP:port of the Docker instance)\n",
    "morphkit.analyze_word_with_morpheus('e)/sxaton',baseUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d238b0-b01e-4bce-9362-97bbfff28076",
   "metadata": {},
   "source": [
    "# 3 - Production <a class=\"anchor\" id=\"bullet3\"></a>\n",
    "##### [Back to ToC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeae073-5aae-438a-bb52-7be49110a4af",
   "metadata": {},
   "source": [
    "## 3.1 - Load the input words <a class=\"anchor\" id=\"bullet3x1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcae575e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 38 words.\n"
     ]
    }
   ],
   "source": [
    "inputFile = \"testset.txt\"\n",
    "with open(inputFile, \"r\", encoding=\"utf-8\") as f:\n",
    "    greekWords = [line.strip() for line in f if line.strip()]\n",
    "print(f\"Loaded {len(greekWords)} words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909fdac-d17f-4211-8f15-ce9cbaca9919",
   "metadata": {},
   "source": [
    "## 3.2 - Running the production <a class=\"anchor\" id=\"bullet3x2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbf2d63-2538-4593-876a-99145b181482",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'greekWords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m baseUrl \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://10.0.1.156:1315/greek/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mgreekWords\u001b[49m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing words\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m         entry \u001b[38;5;241m=\u001b[39m morphkit\u001b[38;5;241m.\u001b[39manalyze_word_with_morpheus(word, baseUrl)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'greekWords' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main Morpheus Analyzer\n",
    "\n",
    "This script takes a list of Greek words in Betacode (loaded before to greekWords),\n",
    "queries the local Morpheus service for each, and collects all parsed\n",
    "morphological analyses into a single JSON file.\n",
    "\n",
    "Workflow:\n",
    "  1. Iterate over each word in `greekWords`, showing progress via tqdm.\n",
    "  2. For each word, call `analyze_word_with_morpheus` to fetch and parse\n",
    "     Morpheus’s output into a structured entry.\n",
    "  3. Extract the `\"analyses\"` list from each entry and append it to `results`.\n",
    "  4. After all words have been processed, serialize `results` to\n",
    "     `morpheus_results.json` with pretty indentation.\n",
    "\n",
    "Result:\n",
    "  A JSON array where each element is the list of parse dictionaries\n",
    "  (one per candidate analysis) returned by Morpheus for one input word.\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from tqdm.std import tqdm\n",
    "\n",
    "baseUrl = \"http://10.0.1.156:1315/greek/\"\n",
    "results = []\n",
    "\n",
    "for word in tqdm(greekWords, desc=\"Processing words\"):\n",
    "    try:\n",
    "        entry = morphkit.analyze_word_with_morpheus(word, baseUrl)\n",
    "        results.append(entry[\"analyses\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {word!r}: {e}\")\n",
    "\n",
    "# write out to JSON\n",
    "with open(\"morpheus_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50919f0e-290a-4eed-ad9a-c880e6e22d43",
   "metadata": {},
   "source": [
    "# 4 - Validation <a class=\"anchor\" id=\"bullet4\"></a>\n",
    "##### [Back to ToC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ae98d-603c-450c-9178-09999374f571",
   "metadata": {},
   "source": [
    "## 4.1 - Load the test file <a class=\"anchor\" id=\"bullet4x1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b6ca7f-6475-4677-8320-c139cad8a43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 38 words.\n"
     ]
    }
   ],
   "source": [
    "inputFile = \"testset.txt\"\n",
    "with open(inputFile, \"r\", encoding=\"utf-8\") as f:\n",
    "    testWords = [line.strip() for line in f if line.strip()]\n",
    "print(f\"Loaded {len(greekWords)} words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329dfc5f-d091-4c71-8a43-26713087c07b",
   "metadata": {},
   "source": [
    "## 4.2 - Run the test file <a class=\"anchor\" id=\"bullet4x2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b139c5e0-b09a-4576-8021-b762e56ceae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing words: 100%|██████████| 1055/1055 [00:22<00:00, 45.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Test Summary</h2><p>Total cases: 1055<br>Matches: 411<br>Close match: 508<br>No-matches: 126</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Wrote results to SP-tag-analysis.htm</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comparing Morpheus and SP-tags\n",
    "\n",
    "Reads a tab separated file with Betacode words and expected SP-tags, then it\n",
    "calls Morpheus via `analyze_word_with_morpheus` to fetch and parse each form. \n",
    "Next it flattens multi-tags into individual codes, and checks for matches.\n",
    "The script generates a color-coded HTML report showing, for each entry:\n",
    "  • the input and expected tag with match/no-match indication\n",
    "  • collapsible raw-block from Morpheus and a collapsible JSON dump\n",
    "The result is writen to file `SP-tag-analysis.htm` (to be opened in a browser)\n",
    "together with display of a brief summary in the notebook.\n",
    "\"\"\"\n",
    "\n",
    "debug=False\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import html\n",
    "import beta_code\n",
    "from IPython.display import display, HTML\n",
    "import traceback\n",
    "from tqdm.std import tqdm\n",
    "\n",
    "baseUrl = \"http://10.0.1.156:1315/greek/\"\n",
    "\n",
    "# path to your failure log\n",
    "fail_log_path = \"failures.txt\"\n",
    "# ensure it exists (or clear it) before the run\n",
    "open(fail_log_path, \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "def format_string(s):\n",
    "    if not s:\n",
    "        return \"<pre>empty</pre>\"\n",
    "\n",
    "    lines = []\n",
    "    for sublist in s:\n",
    "        line = ', '.join(sublist)\n",
    "        lines.append(line)\n",
    "\n",
    "    formatted_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        items = line.split(', ')\n",
    "        formatted_items = []\n",
    "\n",
    "        for item in items:\n",
    "            item = re.sub(r'\\t', '    ', item)\n",
    "            item = re.sub(r':raw', '\\n:raw', item)\n",
    "            item = item.strip(\"'\")  # remove quotes\n",
    "            formatted_items.append(item)\n",
    "\n",
    "        formatted_line = '\\n'.join(formatted_items)\n",
    "        formatted_lines.append(formatted_line)\n",
    "\n",
    "    if not formatted_lines:\n",
    "        return \"<pre></pre>\"\n",
    "\n",
    "    formatted_string = '\\n'.join(formatted_lines)\n",
    "    html_string = f\"<pre>\\n{formatted_string}\\n</pre>\"\n",
    "    return html_string\n",
    "\n",
    "\n",
    "def flatten_tags(analyses):\n",
    "    \"\"\"\n",
    "    Given a list of parse‐dicts, return a sorted list of\n",
    "    individual SP‐tags (splitting any \"V-PAP-DSM/V-PAP-DSN\" etc.).\n",
    "    \"\"\"\n",
    "    flat = set()\n",
    "    for p in analyses:\n",
    "        tag = p.get(\"sp_morph_tag\") or \"\"\n",
    "        # skip if there's no tag\n",
    "        if not tag.strip():\n",
    "            continue\n",
    "        # split on \"/\" and add each non-empty part\n",
    "        for part in tag.split(\"/\"):\n",
    "            part = part.strip()\n",
    "            if part:\n",
    "                flat.add(part)\n",
    "    return sorted(flat)\n",
    "    \n",
    "\n",
    "tests = []\n",
    "# --- load testset --------------------------------------\n",
    "# inputfile = 'problems.txt' # the words where no or no close match was found during last run\n",
    "# inputfile = 'testset.txt' # sample testset (small with a few different types of tags)\n",
    "inputfile = 'beta_morph_pairs.txt' # large set (one word for each morph tags found in the GNT)\n",
    "with open(inputfile, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        if not row or row[0].startswith('#'):\n",
    "            continue\n",
    "        tests.append({\n",
    "            'word_betacode':  row[0].strip(),\n",
    "            'expected_sp_tag': row[1].strip()\n",
    "        })\n",
    "\n",
    "total, passed, close_count, no_block_count, failed = len(tests), 0, 0, 0, 0\n",
    "HTMLobject = \"\"\n",
    "close_threshold = 0.8  # adjustable threshold for “close match”\n",
    "\n",
    "# --- run tests ----------------------------------------\n",
    "\n",
    "# Start building the HTML, including our tooltip‐CSS in the <head>\n",
    "HTMLtotal = '''<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>SP-Tag Test Results</title>\n",
    "  <style>\n",
    "    body { font-family: sans-serif; padding: 20px; }\n",
    "\n",
    "    /* Tooltip container */\n",
    "    .tooltip {\n",
    "      position: relative;\n",
    "      display: inline-block;\n",
    "    }\n",
    "    /* Hidden content */\n",
    "    .tooltip .tooltip-content {\n",
    "      visibility: hidden;\n",
    "      background: white;\n",
    "      color: black;\n",
    "      text-align: left;\n",
    "      border: 1px solid #ccc;\n",
    "      padding: 6px;\n",
    "      position: absolute;\n",
    "      z-index: 100;\n",
    "      top: 100%;\n",
    "      left: 50%;\n",
    "      transform: translateX(-20%);\n",
    "      white-space: nowrap;\n",
    "    }\n",
    "    /* Show on hover */\n",
    "    .tooltip:hover .tooltip-content {\n",
    "      visibility: visible;\n",
    "    }\n",
    "    /* Table styling */\n",
    "    .tooltip-content table {\n",
    "      border-collapse: collapse;\n",
    "      font-family: monospace;\n",
    "      font-size: 12px;\n",
    "    }\n",
    "    .tooltip-content th,\n",
    "    .tooltip-content td {\n",
    "      border: 1px solid #ddd;\n",
    "      padding: 2px 6px;\n",
    "    }\n",
    "    .tooltip-content th {\n",
    "      background: #f0f0f0;\n",
    "    }\n",
    "\n",
    "    .no-block { opacity: 0.6; }\n",
    "  </style>\n",
    "  <script>\n",
    "// toggle all elements of class `cat`\n",
    "function toggleFilter(cat) {\n",
    "  const elems = document.getElementsByClassName(cat);\n",
    "  for (let e of elems) {\n",
    "    e.style.display = (e.style.display === 'none') ? 'block' : 'none';\n",
    "  }\n",
    "}\n",
    "</script>\n",
    "</head><body>\n",
    "'''\n",
    "\n",
    "for item in tqdm(tests, desc=\"Processing words\"):\n",
    "#for item in tests:\n",
    "    wb       = item['word_betacode']\n",
    "    expected = item['expected_sp_tag']\n",
    "    uni      = beta_code.beta_code_to_greek(wb)\n",
    "\n",
    "    try:\n",
    "        entry = morphkit.analyze_word_with_morpheus(wb, baseUrl, debug=False)\n",
    "    except Exception as e:\n",
    "        print(f'Failing word: {wb} with error: {e}')\n",
    "        failed += 1\n",
    "        if debug:\n",
    "            # Print the full stack trace to stderr\n",
    "            tb_str = traceback.format_exc()\n",
    "            print(f'Trace: {tb_str}')\n",
    "        continue\n",
    "\n",
    "    # — check for no Morpheus blocks —\n",
    "    has_blocks = bool(entry.get(\"blocks\"))\n",
    "    if not has_blocks:\n",
    "        # mark this entry so we can style it later\n",
    "        no_block = True\n",
    "    else:\n",
    "        no_block = False\n",
    "\n",
    "    actual_list = flatten_tags(entry[\"analyses\"])\n",
    "    ok          = expected in actual_list\n",
    "\n",
    "    # Compare each generated tag\n",
    "    sim_results = [morphkit.compare_tags(expected, tag, debug=False) for tag in actual_list]\n",
    "    sim_results.sort(key=lambda r: r['overall_similarity'], reverse=True)\n",
    "\n",
    "    # Determine main category/color\n",
    "    if not has_blocks:\n",
    "        category, color = \"no-block\", \"gray\" ; no_block_count+=1\n",
    "    elif ok:\n",
    "        category, color = \"match\", \"green\"; passed += 1\n",
    "    elif any(r['overall_similarity'] >= close_threshold for r in sim_results):\n",
    "        category, color = \"close-match\", \"orange\"; close_count += 1\n",
    "    else:\n",
    "        category, color = \"no-match\", \"red\"; failed += 1\n",
    "        with open(fail_log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{wb}\\t{expected}\\n\")\n",
    "\n",
    "    # Build links with HTML‐table tooltips\n",
    "    sim_links = []\n",
    "    table_html_parts = []\n",
    "        \n",
    "    for result in sim_results:\n",
    "        tag = result[\"tag1\"]\n",
    "        details = result[\"details\"]\n",
    "    \n",
    "        total_raw = 0.0\n",
    "        total_weight = 0\n",
    "        # Header row\n",
    "        rows = [\n",
    "            \"<tr>\"\n",
    "            \"<th>Feature</th><th>N1904-TF</th><th>Morpheus</th>\"\n",
    "            \"<th>Sim</th><th>Wt</th><th>Contrib</th>\"\n",
    "            \"</tr>\"\n",
    "        ]\n",
    "    \n",
    "        # Build one row per feature\n",
    "        for feat, dv in details.items():\n",
    "            kv = html.escape(str(dv[\"tag1\"]))  # N1904-TF\n",
    "            gv = html.escape(str(dv[\"tag2\"]))  # Morpheus \n",
    "            s  = dv[\"similarity\"]\n",
    "            w  = dv[\"weight\"]\n",
    "            contrib = s * w\n",
    "    \n",
    "            total_raw    += contrib\n",
    "            total_weight += w\n",
    "    \n",
    "            rows.append(\n",
    "                \"<tr>\"\n",
    "                f\"<td>{feat}</td>\"\n",
    "                f\"<td>{kv}</td>\"\n",
    "                f\"<td>{gv}</td>\"\n",
    "                f\"<td>{s:.2f}</td>\"\n",
    "                f\"<td>{w}</td>\"\n",
    "                f\"<td>{contrib:.2f}</td>\"\n",
    "                \"</tr>\"\n",
    "            )\n",
    "    \n",
    "        # Totals row\n",
    "        rows.append(\n",
    "            \"<tr style='font-weight:bold'>\"\n",
    "            \"<td>Total raw</td><td></td><td></td>\"\n",
    "            f\"<td></td><td>{total_weight}</td><td>{total_raw:.2f}</td>\"\n",
    "            \"</tr>\"\n",
    "        )\n",
    "        # Normalized similarity row\n",
    "        normalized = (total_raw / total_weight) if total_weight else 0.0\n",
    "        rows.append(\n",
    "            \"<tr style='font-weight:bold'>\"\n",
    "            \"<td>Normalized</td><td></td><td></td>\"\n",
    "            f\"<td>{normalized:.3f}</td><td></td><td></td>\"\n",
    "            \"</tr>\"\n",
    "        )\n",
    "        \n",
    "        # Wrap up this tag’s table \n",
    "        table_html = (\n",
    "            f\"<h3>Analysis for tag: {html.escape(tag)}</h3>\"\n",
    "            \"<table>\"\n",
    "            + \"\".join(rows) +\n",
    "            \"</table>\"\n",
    "        )\n",
    "\n",
    "        # Determine similairity color\n",
    "        if normalized == 1: \n",
    "            item_color='green'\n",
    "        elif normalized >= close_threshold:\n",
    "            item_color='orange'\n",
    "        else:\n",
    "            item_color='red'\n",
    "\n",
    "        # Tooltip wrapper\n",
    "        sim_links.append(\n",
    "            f'<span class=\"tooltip\">'\n",
    "            f'<a href=\"https://tonyjurg.github.io/'\n",
    "            f'Sandborg-Petersen-decoder/index.html?tag={tag}\" '\n",
    "            f'target=\"decoder\" '\n",
    "            f'style=\"color:inherit;text-decoration:none;\">'\n",
    "            f'{tag}'\n",
    "            f'</a>: '\n",
    "            f'<span style=\"color:{item_color};\">{normalized:.2f}</span>'\n",
    "            f'<div class=\"tooltip-content\">{table_html}</div>'\n",
    "            f'</span>'\n",
    "        )\n",
    "\n",
    "    sim_str = \", \".join(sim_links)\n",
    "\n",
    "    # Append this word’s block\n",
    "    HTMLobject += (\n",
    "        f'\\n<!-- entry-->\\n<div id=\"entry-{wb}\" class=\"entry {category}\">'\n",
    "        f'<div style=\"color:{color};font-weight:bold;\">'\n",
    "        f'<a href=\"https://www.perseus.tufts.edu/hopper//morph?l={wb}&la=greek\" '\n",
    "        f'target=\"perseus\" style=\"color:black;text-decoration:none;\">{wb}</a> '\n",
    "        f'({uni}) ⇒ {category}</div>\\n'\n",
    "        f'<div style=\"font-weight:bold;\">'\n",
    "        f'N1904-TF: '\n",
    "        f'<a href=\"https://tonyjurg.github.io/Sandborg-Petersen-decoder/index.html?tag={expected}\" '\n",
    "        f'target=\"decoder\" style=\"color:black;text-decoration:none;\">{expected}</a>'\n",
    "        f'</div>\\n'\n",
    "        f'<div style=\"font-weight:bold;\">Morpheus: {sim_str}</div><br>\\n'\n",
    "        f'<details><summary>Morpheus blocks</summary>{format_string(entry[\"blocks\"])}</details>\\n'\n",
    "        f'<details><summary>Parsed JSON</summary>'\n",
    "        f'<pre style=\"background:#f7f7f7;padding:10px;border:1px solid #ddd;'\n",
    "        f'overflow:auto;white-space:pre-wrap;\">'\n",
    "        f'{html.escape(json.dumps(entry[\"analyses\"], indent=4, ensure_ascii=False))}'\n",
    "        f'</pre></details>\\n<hr/></div>\\n'\n",
    "    )\n",
    "\n",
    "\n",
    "HTMLtotal += (f'<h1>Morph tag matching between N1904-TF and Morpheus</h1>'\n",
    "            f'<h2>Test results summary</h2>'\n",
    "            f'<p>Inputfile: {inputfile}</p>'\n",
    "            f'<p>counts:</p><ul>'\n",
    "            f'<li>Total: {total}</li>'\n",
    "            f'<li><span style=\"color:green;\" >Match: {passed}</span> <span onclick=\"toggleFilter(\\'match\\')\">(hide/show)</span></li>'\n",
    "            f'<li><span style=\"color:orange;\" >Close match: {close_count}</span> (treshold={close_threshold}) <span onclick=\"toggleFilter(\\'close-match\\')\">(hide/show)</span></li>'\n",
    "            f'<li><span style=\"color:red;\" >No match: {failed}</span> <span onclick=\"toggleFilter(\\'no-match\\')\">(hide/show)</span></li>'\n",
    "            f'<li><span style=\"color:gray;\" >No Morpheus block received: {no_block_count}</span> <span onclick=\"toggleFilter(\\'no-block\\')\">(hide/show)</span></li></ul></p>\\n'\n",
    "            f'<h2>Detailed test results</h2>'\n",
    ")\n",
    "\n",
    "HTMLtotal += HTMLobject\n",
    "\n",
    "# Close out HTML\n",
    "HTMLtotal += \"</body></html>\"\n",
    "\n",
    "# Write & display as before…\n",
    "with open(\"SP-tag-analysis.htm\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(HTMLtotal)\n",
    "\n",
    "\n",
    "display(HTML(f'<h2>Test Summary</h2><p>Total cases: {total}<br>Matches: {passed}<br>Close match: {close_count}<br>No-matches: {failed}</p>'))\n",
    "display(HTML('<p>Wrote results to SP-tag-analysis.htm</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1669ca26-94f1-49cc-8602-09fc23274988",
   "metadata": {},
   "source": [
    "# THE MULTI LEMMA VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c566dcb-5f18-444e-895c-d045fa8954a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing words: 100%|██████████| 1055/1055 [00:27<00:00, 38.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Test Summary</h2><p>Total cases: 1055<br>Matches: 0<br>Close match: 0<br>No-matches: 0</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Wrote results to SP-tag-analysis.htm</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comparing Morpheus and SP-tags\n",
    "\n",
    "Reads a tab separated file with Betacode words and expected SP-tags, then it\n",
    "calls Morpheus via `analyze_word_with_morpheus` to fetch and parse each form. \n",
    "Next it flattens multi-tags into individual codes, and checks for matches.\n",
    "The script generates a color-coded HTML report showing, for each entry:\n",
    "  • the input and expected tag with match/no-match indication\n",
    "  • collapsible raw-block from Morpheus and a collapsible JSON dump\n",
    "The result is writen to file `SP-tag-analysis.htm` (to be opened in a browser)\n",
    "together with display of a brief summary in the notebook.\n",
    "\"\"\"\n",
    "\n",
    "debug=False\n",
    "\n",
    "HTMLtotal=''\n",
    "import csv\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import html\n",
    "import beta_code\n",
    "from IPython.display import display, HTML\n",
    "import traceback\n",
    "import urllib.parse\n",
    "from collections import defaultdict\n",
    "from tqdm.std import tqdm\n",
    "\n",
    "baseUrl = \"http://10.0.1.156:1315/greek/\"\n",
    "\n",
    "# path to your failure log\n",
    "fail_log_path = \"failures.txt\"\n",
    "# ensure it exists (or clear it) before the run\n",
    "open(fail_log_path, \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "def format_string(s):\n",
    "    if not s:\n",
    "        return \"<pre>empty</pre>\"\n",
    "\n",
    "    lines = []\n",
    "    for sublist in s:\n",
    "        line = ', '.join(sublist)\n",
    "        lines.append(line)\n",
    "\n",
    "    formatted_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        items = line.split(', ')\n",
    "        formatted_items = []\n",
    "\n",
    "        for item in items:\n",
    "            item = re.sub(r'\\t', '    ', item)\n",
    "            item = re.sub(r':raw', '\\n:raw', item)\n",
    "            item = item.strip(\"'\")  # remove quotes\n",
    "            formatted_items.append(item)\n",
    "\n",
    "        formatted_line = '\\n'.join(formatted_items)\n",
    "        formatted_lines.append(formatted_line)\n",
    "\n",
    "    if not formatted_lines:\n",
    "        return \"<pre></pre>\"\n",
    "\n",
    "    formatted_string = '\\n'.join(formatted_lines)\n",
    "    html_string = f\"<pre>\\n{formatted_string}\\n</pre>\"\n",
    "    return html_string\n",
    "\n",
    "\n",
    "def flatten_tags(analyses):\n",
    "    \"\"\"\n",
    "    Given a list of parse‐dicts, return a sorted list of\n",
    "    individual SP‐tags (splitting any \"V-PAP-DSM/V-PAP-DSN\" etc.).\n",
    "    \"\"\"\n",
    "    flat = set()\n",
    "    for p in analyses:\n",
    "        tag = p.get(\"sp_morph_tag\") or \"\"\n",
    "        # skip if there's no tag\n",
    "        if not tag.strip():\n",
    "            continue\n",
    "        # split on \"/\" and add each non-empty part\n",
    "        for part in tag.split(\"/\"):\n",
    "            part = part.strip()\n",
    "            if part:\n",
    "                flat.add(part)\n",
    "    return sorted(flat)\n",
    "    \n",
    "\n",
    "tests = []\n",
    "# --- load testset --------------------------------------\n",
    "#inputfile = 'problems.txt' # the words where no or no close match was found during last run\n",
    "inputfile = 'test-set.txt' # sample testset (small with a few different types of tags)\n",
    "#inputfile = 'beta_morph_pairs.txt' # large set (one word for each morph tags found in the GNT)\n",
    "with open(inputfile, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        if not row or row[0].startswith('#'):\n",
    "            continue\n",
    "        tests.append({\n",
    "            'word_betacode':  row[0].strip(),\n",
    "            'expected_sp_tag': row[1].strip()\n",
    "        })\n",
    "\n",
    "total, passed, close_count, no_block_count, failed = len(tests), 0, 0, 0, 0\n",
    "close_threshold = 0.8  # adjustable threshold for “close match”\n",
    "\n",
    "# --- run tests ----------------------------------------\n",
    "\n",
    "# Start building the HTML, including our tooltip‐CSS in the <head>\n",
    "HTMLstart = '''<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>SP-Tag Test Results</title>\n",
    "  <style>\n",
    "    body { font-family: sans-serif; padding: 20px; }\n",
    "\n",
    "    /* Tooltip container */\n",
    "    .tooltip {\n",
    "      position: relative;\n",
    "      display: inline-block;\n",
    "      cursor: help;\n",
    "    }\n",
    "    /* Hidden content */\n",
    "    .tooltip .tooltip-content {\n",
    "      visibility: hidden;\n",
    "      background: white;\n",
    "      color: black;\n",
    "      text-align: left;\n",
    "      border: 1px solid #ccc;\n",
    "      padding: 6px;\n",
    "      position: absolute;\n",
    "      z-index: 100;\n",
    "      top: 100%;\n",
    "      left: 50%;\n",
    "      transform: translateX(-20%);\n",
    "      white-space: nowrap;\n",
    "    }\n",
    "    /* Show on hover */\n",
    "    .tooltip:hover .tooltip-content {\n",
    "      visibility: visible;\n",
    "    }\n",
    "    /* Table styling */\n",
    "    .tooltip-content table {\n",
    "      border-collapse: collapse;\n",
    "      font-family: monospace;\n",
    "      font-size: 12px;\n",
    "    }\n",
    "    .tooltip-content th,\n",
    "    .tooltip-content td {\n",
    "      border: 1px solid #ddd;\n",
    "      padding: 2px 6px;\n",
    "    }\n",
    "    .tooltip-content th {\n",
    "      background: #f0f0f0;\n",
    "    }\n",
    "\n",
    "    .no-block { opacity: 0.6; }\n",
    "  </style>\n",
    "  \n",
    "  <script>\n",
    "// toggle all elements of class `cat`\n",
    "function toggleFilter(cat) {\n",
    "  const elems = document.getElementsByClassName(cat);\n",
    "  for (let e of elems) {\n",
    "    e.style.display = (e.style.display === 'none') ? 'block' : 'none';\n",
    "  }\n",
    "}\n",
    "</script>\n",
    "</head><body>\n",
    "'''\n",
    "\n",
    "\n",
    "for item in tqdm(tests, desc=\"Processing words\"):\n",
    "    wb       = item['word_betacode']\n",
    "    expected = item['expected_sp_tag']\n",
    "    uni      = beta_code.beta_code_to_greek(wb)\n",
    "\n",
    "    try:\n",
    "        entry = morphkit.analyze_word_with_morpheus(wb, baseUrl, debug=False)\n",
    "    except Exception as e:\n",
    "        print(f'Failing word: {wb} with error: {e}')\n",
    "        failed += 1\n",
    "        if debug:\n",
    "            # Print the full stack trace to stderr\n",
    "            print(traceback.format_exc(), file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    # — check for no Morpheus blocks —\n",
    "    has_blocks = bool(entry.get(\"blocks\"))\n",
    "    no_block   = not has_blocks\n",
    "\n",
    "    # Group analyses by their lemma_beta\n",
    "    lemma_groups = defaultdict(list)\n",
    "    for parse in entry.get(\"analyses\", []):\n",
    "        # get the raw betacode (might be None), then drop all '*' markers\n",
    "        lemma = (parse.get(\"lemma_beta\", \"\") or \"\").replace(\"*\", \"\")\n",
    "        lemma_groups[lemma].append(parse)\n",
    "\n",
    "    # Start the outer entry div for this word\n",
    "    HTMLobject += (\n",
    "        f'\\n<!-- entry for {wb} -->\\n'\n",
    "        f'<div id=\"entry-{wb}\" class=\"entry\">\\n'\n",
    "        f'<h2><a href=\"https://www.perseus.tufts.edu/hopper/morph?l={wb}&la=greek\" '\n",
    "        f'target=\"perseus\" style=\"color:black;text-decoration:none;\">{wb} ({uni})</a></h2>\\n'\n",
    "    )\n",
    "\n",
    "    # If no blocks at all, show a single UNK‐style line and close\n",
    "    if no_block:\n",
    "        no_block_count += 1\n",
    "        HTMLobject += (\n",
    "            f'  <div style=\"color:gray;font-weight:bold;\">no-block</div>\\n'\n",
    "            f'</div>\\n<hr/>\\n'\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # Otherwise, iterate each lemma subgroup\n",
    "    for lemma_beta, parses in lemma_groups.items():\n",
    "        lemma_uni = beta_code.beta_code_to_greek(lemma_beta)\n",
    "        # Flatten tags for this lemma only\n",
    "        actual_list = flatten_tags(parses)\n",
    "        ok          = expected in actual_list\n",
    "\n",
    "        # Build similarity results\n",
    "        sim_results = [\n",
    "            morphkit.compare_tags(expected, tag, debug=False)\n",
    "            for tag in actual_list\n",
    "        ]\n",
    "        sim_results.sort(key=lambda r: r['overall_similarity'], reverse=True)\n",
    "\n",
    "        # Pick a category/color per lemma\n",
    "        if ok:\n",
    "            category, color = \"match\", \"green\"\n",
    "            passed += 1\n",
    "        elif any(r['overall_similarity'] >= close_threshold for r in sim_results):\n",
    "            category, color = \"close-match\", \"orange\"\n",
    "            close_count += 1\n",
    "        else:\n",
    "            category, color = \"no-match\", \"red\"\n",
    "            failed += 1\n",
    "            with open(fail_log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"{wb}\\t{lemma_beta}\\t{expected}\\n\")\n",
    "\n",
    "        # Lemma header\n",
    "        HTMLobject += (\n",
    "            f'  <div class=\"lemma-group\" style=\"margin-left:1em;\"  class=\"{category}\">\\n'\n",
    "            f'    <h4>Lemma: {lemma_beta} ({lemma_uni}) '\n",
    "            f'<span style=\"color:{color};font-weight:bold;\">[{category}]</span></h4>\\n'\n",
    "        )\n",
    "\n",
    "        # Build tooltip links exactly as before\n",
    "        sim_links = []\n",
    "        for result in sim_results:\n",
    "            tag     = result[\"tag1\"]\n",
    "            details = result[\"details\"]\n",
    "\n",
    "            total_raw = 0.0\n",
    "            total_wt  = 0\n",
    "            rows = [\"<tr><th>Feature</th><th>TF</th><th>Mph</th><th>Sim</th><th>Wt</th><th>Contrib</th></tr>\"]\n",
    "            for feat, dv in details.items():\n",
    "                kv      = html.escape(str(dv[\"tag1\"])) # N1904-TF\n",
    "                gv      = html.escape(str(dv[\"tag2\"])) # Morpheus\n",
    "                s       = dv[\"similarity\"]\n",
    "                w       = dv[\"weight\"]\n",
    "                contrib = s * w\n",
    "                total_raw += contrib\n",
    "                total_wt  += w\n",
    "                rows.append(\n",
    "                    \"<tr>\"\n",
    "                    f\"<td>{feat}</td><td>{kv}</td><td>{gv}</td>\"\n",
    "                    f\"<td>{s:.2f}</td><td>{w}</td><td>{contrib:.2f}</td>\"\n",
    "                    \"</tr>\"\n",
    "                )\n",
    "            # totals\n",
    "            rows.append(\n",
    "                \"<tr style='font-weight:bold'>\"\n",
    "                f\"<td>Total</td><td></td><td></td><td></td><td>{total_wt}</td><td>{total_raw:.2f}</td>\"\n",
    "                \"</tr>\"\n",
    "            )\n",
    "            norm = (total_raw / total_wt) if total_wt else 0.0\n",
    "            rows.append(\n",
    "                \"<tr style='font-weight:bold'>\"\n",
    "                f\"<td>Norm</td><td></td><td></td><td>{norm:.3f}</td><td></td><td></td>\"\n",
    "                \"</tr>\"\n",
    "            )\n",
    "\n",
    "            table_html = (\n",
    "                f\"<h4>Tag: {html.escape(tag)}</h4>\"\n",
    "                \"<table>\" + \"\".join(rows) + \"</table>\"\n",
    "            )\n",
    "\n",
    "            # color by similarity\n",
    "            item_color = (\n",
    "                \"green\" if norm == 1\n",
    "                else \"orange\" if norm >= close_threshold\n",
    "                else \"red\"\n",
    "            )\n",
    "\n",
    "            sim_links.append(\n",
    "                f'<span class=\"tooltip\">'\n",
    "                f'<a href=\"https://tonyjurg.github.io/Sandborg-Petersen-decoder/index.html?tag={tag}\" '\n",
    "                f'target=\"decoder\" style=\"text-decoration:none;\">{tag}</a>: '\n",
    "                f'<span style=\"color:{item_color};\">{norm:.2f}</span>'\n",
    "                f'<div class=\"tooltip-content\">{table_html}</div>'\n",
    "                f'</span>'\n",
    "            )\n",
    "\n",
    "        # Render the TF vs Morpheus line with all tooltips\n",
    "        HTMLobject += (\n",
    "            f'<div>'\n",
    "            f'<strong>N1904-TF:</strong> '\n",
    "            f'<a href=\"https://tonyjurg.github.io/Sandborg-Petersen-decoder/index.html?tag={expected}\" '\n",
    "            f'target=\"decoder\" style=\"text-decoration:none;\">{expected}</a></div>\\n'\n",
    "            f'<div><strong>Morpheus:</strong>' \n",
    "            + \", \".join(sim_links) +\n",
    "            \"</div>\\n\"\n",
    "        )\n",
    "\n",
    "        # Blocks and JSON for this lemma\n",
    "        HTMLobject += (\n",
    "            f'    <details><summary>Blocks</summary>'\n",
    "            f'{format_string(entry[\"blocks\"])}</details>\\n'\n",
    "            f'    <details><summary>JSON</summary>'\n",
    "            f'<pre>{html.escape(json.dumps(parses, indent=2, ensure_ascii=False))}</pre>'\n",
    "            f'</details>\\n'\n",
    "            f'  </div>\\n'\n",
    "        )\n",
    "\n",
    "    # Close the word entry\n",
    "    HTMLobject += '</div>\\n<hr/>\\n'\n",
    "\n",
    "\n",
    "# After loop, wrap up HTMLtotal \n",
    "HTMLtotal =  (HTMLstart +\n",
    "    f'<h1>Morph tag matching between N1904-TF and Morpheus</h1>'\n",
    "    f'<h2>Test results summary</h2>'\n",
    "    f'<p>Inputfile: {inputfile}</p>'\n",
    "    f'<ul>'\n",
    "    f'<li>Total: {total}</li>'\n",
    "    f'<li><span style=\"color:green;\">Match: {passed}</span> '\n",
    "    f'<span onclick=\"toggleFilter(\\'match\\')\">(hide/show)</span></li>'\n",
    "    f'<li><span style=\"color:orange;\">Close match: {close_count}</span> '\n",
    "    f'(threshold={close_threshold}) '\n",
    "    f'<span onclick=\"toggleFilter(\\'close-match\\')\">(hide/show)</span></li>'\n",
    "    f'<li><span style=\"color:red;\">No match: {failed}</span> '\n",
    "    f'<span onclick=\"toggleFilter(\\'no-match\\')\">(hide/show)</span></li>'\n",
    "    f'<li><span style=\"color:gray;\">No Morpheus block received: {no_block_count}</span> '\n",
    "    f'<span onclick=\"toggleFilter(\\'no-block\\')\">(hide/show)</span></li>'\n",
    "    f'</ul>\\n'\n",
    "    f'<h2>Detailed test results</h2>\\n'\n",
    "    + HTMLobject\n",
    ")\n",
    "\n",
    "\n",
    "# Close out HTML\n",
    "HTMLtotal += \"</body></html>\"\n",
    "\n",
    "# Write & display as before…\n",
    "with open(\"SP-tag-analysis_M.htm\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(HTMLtotal)\n",
    "\n",
    "\n",
    "display(HTML(f'<h2>Test Summary</h2><p>Total cases: {total}<br>Matches: {passed}<br>Close match: {close_count}<br>No-matches: {failed}</p>'))\n",
    "display(HTML('<p>Wrote results to SP-tag-analysis.htm</p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58edf7e-abbb-4b03-9d78-b6b5f2bf0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also display in notebook (dit werkt maar levert echt heeeel veeel data op...)\n",
    "display(HTML(HTMLtotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dca845a-c3c6-4ee4-b09f-26e6d8891cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing words: 100%|██████████| 1055/1055 [00:18<00:00, 57.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Report written to SP-tag-analysis_3.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import html as html_mod\n",
    "from collections import defaultdict\n",
    "from functools import lru_cache\n",
    "from tqdm.std import tqdm\n",
    "\n",
    "import beta_code\n",
    "import morphkit \n",
    "\n",
    "# ————— Configuration —————\n",
    "#inputfile = 'problems.txt' # the words where no or no close match was found during last run\n",
    "#inputfile = 'testset.txt' # sample testset (small with a few different types of tags)\n",
    "#inputfile = 'beta_morph_pairs.txt' # large set (one word for each morph tags found in the GNT)\n",
    "INPUT_FILE   = \"beta_morph_pairs.txt\"          # TSV: word_betacode \\t expected_sp_tag\n",
    "OUTPUT_FILE  = \"SP-tag-analysis_3.html\"\n",
    "BASE_URL     = \"http://10.0.1.156:1315/greek/\"\n",
    "CLOSE_THRESH = 0.8\n",
    "# ———————————————————————\n",
    "\n",
    "# 1) Caches\n",
    "@lru_cache(maxsize=None)\n",
    "def fetch_analysis(word_betacode):\n",
    "    return morphkit.analyze_word_with_morpheus(word_betacode, BASE_URL, debug=False)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def to_greek(word_betacode):\n",
    "    return beta_code.beta_code_to_greek(word_betacode)\n",
    "\n",
    "# 2) Helpers\n",
    "def flatten_tags(analyses):\n",
    "    flat = set()\n",
    "    for p in analyses:\n",
    "        for part in (p.get(\"sp_morph_tag\") or \"\").split(\"/\"):\n",
    "            part = part.strip()\n",
    "            if part:\n",
    "                flat.add(part)\n",
    "    return sorted(flat)\n",
    "\n",
    "ROW_TMPL = (\n",
    "    \"<tr>\"\n",
    "    \"<td>{feat}</td>\"\n",
    "    \"<td>{known}</td>\"\n",
    "    \"<td>{gen}</td>\"\n",
    "    \"<td>{sim:.2f}</td>\"\n",
    "    \"<td>{wt}</td>\"\n",
    "    \"<td>{contrib:.2f}</td>\"\n",
    "    \"</tr>\"\n",
    ")\n",
    "\n",
    "def make_table(details):\n",
    "    parts = [\n",
    "        \"<tr>\"\n",
    "        \"<th>Feature</th><th>TF</th><th>Mph</th>\"\n",
    "        \"<th>Sim</th><th>Wt</th><th>Contrib</th>\"\n",
    "        \"</tr>\"\n",
    "    ]\n",
    "    total_raw = 0.0\n",
    "    total_wt  = 0\n",
    "    for feat, dv in details.items():\n",
    "        known   = html_mod.escape(str(dv[\"tag1\"] or \"\"))  #N1904-TF\n",
    "        gen     = html_mod.escape(str(dv[\"tag2\"] or \"\")) #Morpheus\n",
    "        sim     = dv[\"similarity\"]\n",
    "        wt      = dv[\"weight\"]\n",
    "        contrib = sim * wt\n",
    "        total_raw += contrib\n",
    "        total_wt  += wt\n",
    "        parts.append(ROW_TMPL.format(\n",
    "            feat=feat, known=known, gen=gen, sim=sim, wt=wt, contrib=contrib\n",
    "        ))\n",
    "    parts.append(\n",
    "        \"<tr style='font-weight:bold'>\"\n",
    "        f\"<td>Total</td><td></td><td></td><td></td>\"\n",
    "        f\"<td>{total_wt}</td><td>{total_raw:.2f}</td>\"\n",
    "        \"</tr>\"\n",
    "    )\n",
    "    norm = (total_raw/total_wt) if total_wt else 0.0\n",
    "    parts.append(\n",
    "        \"<tr style='font-weight:bold'>\"\n",
    "        f\"<td>Norm</td><td></td><td></td>\"\n",
    "        f\"<td>{norm:.3f}</td><td></td><td></td>\"\n",
    "        \"</tr>\"\n",
    "    )\n",
    "    return \"<table>\" + \"\".join(parts) + \"</table>\"\n",
    "\n",
    "def format_blocks(blocks):\n",
    "    if not blocks:\n",
    "        return \"<pre>empty</pre>\"\n",
    "    lines = []\n",
    "    for sub in blocks:\n",
    "        line = \", \".join(sub)\n",
    "        line = line.replace(\"\\t\", \"    \").replace(\":raw\", \"\\n:raw\")\n",
    "        lines.append(line.strip(\"'\"))\n",
    "    return \"<pre>\\n\" + \"\\n\".join(lines) + \"\\n</pre>\"\n",
    "\n",
    "# 3) Load tests\n",
    "tests = []\n",
    "with open(INPUT_FILE, newline=\"\", encoding=\"utf-8\") as f:\n",
    "    rdr = csv.reader(f, delimiter=\"\\t\")\n",
    "    for row in rdr:\n",
    "        if not row or row[0].startswith(\"#\"):\n",
    "            continue\n",
    "        tests.append({\n",
    "            \"word_betacode\":  row[0].strip(),\n",
    "            \"expected_sp_tag\": row[1].strip()\n",
    "        })\n",
    "\n",
    "    # 4) Process and build entries\n",
    "    summary = {\"total\": len(tests), \"passed\":0, \"close\":0, \"failed\":0, \"no_block\":0}\n",
    "    entries = []\n",
    "\n",
    "    for item in tqdm(tests, desc=\"Processing words\"):\n",
    "        wb       = item[\"word_betacode\"]\n",
    "        expected = item[\"expected_sp_tag\"]\n",
    "        uni      = to_greek(wb)\n",
    "    \n",
    "        # fetch analyses\n",
    "        entry = fetch_analysis(wb)\n",
    "        blocks   = entry.get(\"blocks\", [])\n",
    "        analyses = entry.get(\"analyses\", [])\n",
    "        if not blocks:\n",
    "            summary[\"no_block\"] += 1\n",
    "    \n",
    "        # group by lemma_beta (strip '*')\n",
    "        lemma_groups = defaultdict(list)\n",
    "        for p in analyses:\n",
    "            key = (p.get(\"lemma_beta\") or \"\").replace(\"*\",\"\")\n",
    "            lemma_groups[key].append(p)\n",
    "    \n",
    "        # start this word’s HTML\n",
    "        html = []\n",
    "        html.append(f'<div id=\"entry-{wb}\">')\n",
    "        html.append(f'<h2><a href=\"https://www.perseus.tufts.edu/hopper/morph?l={wb}&la=greek\" target=\"_blank\">{wb} ({uni})</a></h2>')\n",
    "    \n",
    "        if not blocks:\n",
    "            html.append('<div class=\"no-block\">no Morpheus blocks</div>')\n",
    "            html.append('</div><hr/>')\n",
    "            entries.append(\"\\n\".join(html))\n",
    "            continue\n",
    "    \n",
    "        # per-lemma subentries\n",
    "        for lemma, parses in lemma_groups.items():\n",
    "            lemma_uni = to_greek(lemma)\n",
    "            tags      = flatten_tags(parses)\n",
    "    \n",
    "            # find best tag & score, stopping on perfect match\n",
    "            best_tag, best_score = None, -1.0\n",
    "            for t in tags:\n",
    "                sc = morphkit.compare_tags(expected, t, debug=False)[\"overall_similarity\"]\n",
    "                if sc > best_score:\n",
    "                    best_tag, best_score = t, sc\n",
    "                    if sc == 1.0:\n",
    "                        break\n",
    "    \n",
    "            # category\n",
    "            if best_score == 1.0:\n",
    "                cat, col = \"match\", \"green\"\n",
    "                summary[\"passed\"] += 1\n",
    "            elif best_score >= CLOSE_THRESH:\n",
    "                cat, col = \"close\", \"orange\"\n",
    "                summary[\"close\"] += 1\n",
    "            else:\n",
    "                cat, col = \"no-match\", \"red\"\n",
    "                summary[\"failed\"] += 1\n",
    "    \n",
    "            html.append(f'<div class=\"lemma-group {cat}\">')\n",
    "            html.append(f'  <h3>Lemma: {lemma} ({lemma_uni}) <span style=\"color:{col};\">[{cat}]</span></h3>')\n",
    "            html.append('  <div><strong>Expected:</strong> '\n",
    "                        f'<a href=\"https://tonyjurg.github.io/Sandborg-Petersen-decoder/index.html?tag={expected}\" target=\"_blank\">{expected}</a></div>')\n",
    "    \n",
    "            # tooltip for best_tag\n",
    "            cmp_res = morphkit.compare_tags(expected, best_tag, debug=False)\n",
    "            table   = make_table(cmp_res[\"details\"])\n",
    "            html.append('  <div><strong>Morpheus:</strong> '\n",
    "                        f'<span class=\"tooltip\">{best_tag} : {best_score:.2f}'\n",
    "                        f'<div class=\"tooltip-content\"><h4>Tag: {best_tag}</h4>{table}</div>'\n",
    "                        '</span></div>')\n",
    "    \n",
    "            # show blocks & JSON only on non-perfect\n",
    "            if cat != \"match\":\n",
    "                html.append('  <details><summary>Blocks</summary>' + format_blocks(blocks) + '</details>')\n",
    "                html.append('  <details><summary>Analyses JSON</summary><pre>' +\n",
    "                            html_mod.escape(json.dumps(parses, indent=2, ensure_ascii=False)) +\n",
    "                            '</pre></details>')\n",
    "    \n",
    "            html.append('</div>')  # close lemma-group\n",
    "    \n",
    "        html.append('</div><hr/>')  # close entry\n",
    "        entries.append(\"\\n\".join(html))\n",
    "\n",
    "    # 5) Write out final HTML\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as out:\n",
    "        # write the header\n",
    "        out.write(f\"\"\"<!DOCTYPE html>\n",
    "        <html lang=\"en\">\n",
    "        <head><meta charset=\"utf-8\">\n",
    "        <title>SP-Tag Analysis</title>\n",
    "        <style>\n",
    "          body {{ font-family:sans-serif; padding:20px }}\n",
    "          .tooltip {{ position:relative; display:inline-block; cursor:help }}\n",
    "          .tooltip .tooltip-content {{ display:none; position:absolute; top:1.2em; left:0;\n",
    "            background:white; border:1px solid #ccc; padding:6px; z-index:100;\n",
    "            white-space:nowrap }}\n",
    "          .tooltip:hover .tooltip-content {{ display:block }}\n",
    "          .tooltip-content table {{ border-collapse:collapse; font-family:monospace; font-size:12px }}\n",
    "          .tooltip-content th, .tooltip-content td {{ border:1px solid #ddd; padding:2px 6px }}\n",
    "          .tooltip-content th {{ background:#f0f0f0 }}\n",
    "          .no-block {{ opacity:0.6; color:gray }}\n",
    "        </style>\n",
    "        </head>\n",
    "        <body>\n",
    "        <h1>SP-Tag Analysis Report</h1>\n",
    "        <ul>\n",
    "          <li>Total words: {summary['total']}</li>\n",
    "          <li>Passed: <span style=\"color:green;\">{summary['passed']}</span></li>\n",
    "          <li>Close: <span style=\"color:orange;\">{summary['close']}</span></li>\n",
    "          <li>Failed: <span style=\"color:red;\">{summary['failed']}</span></li>\n",
    "          <li>No blocks: <span style=\"color:gray;\">{summary['no_block']}</span></li>\n",
    "        </ul>\n",
    "        <hr/>\n",
    "        \"\"\")\n",
    "        \n",
    "        for e in entries:\n",
    "            out.write(e + \"\\n\")\n",
    "        \n",
    "        out.write(\"</body></html>\")\n",
    "\n",
    "print(f\"✅ Report written to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99df86f-0923-4911-adc9-fb1e8b280c5f",
   "metadata": {},
   "source": [
    "# Nu met lemma erbij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c9f331b-80ba-4bb9-a357-7ef165e482c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing words: 100%|██████████| 1055/1055 [00:19<00:00, 53.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Report written to SP-tag-analysis_3.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import html as html_mod\n",
    "from collections import defaultdict\n",
    "from functools import lru_cache\n",
    "from tqdm.std import tqdm\n",
    "\n",
    "import beta_code\n",
    "import morphkit \n",
    "\n",
    "# ————— Configuration —————\n",
    "#inputfile = 'problems.txt' # the words where no or no close match was found during last run\n",
    "#inputfile = 'testset.txt' # sample testset (small with a few different types of tags)\n",
    "#inputfile = 'beta_morph_pairs.txt' # large set (one word for each morph tags found in the GNT)\n",
    "INPUT_FILE   = \"test-set.txt\"          # TSV: word_betacode \\t expected_sp_tag\n",
    "OUTPUT_FILE  = \"SP-tag-analysis_3.html\"\n",
    "BASE_URL     = \"http://10.0.1.156:1315/greek/\"\n",
    "CLOSE_THRESH = 0.8\n",
    "# ———————————————————————\n",
    "\n",
    "# 1) Caches\n",
    "@lru_cache(maxsize=None)\n",
    "def fetch_analysis(word_betacode):\n",
    "    return morphkit.analyze_word_with_morpheus(word_betacode, BASE_URL, debug=False)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def to_greek(word_betacode):\n",
    "    return beta_code.beta_code_to_greek(word_betacode)\n",
    "\n",
    "# 2) Helpers\n",
    "def flatten_tags(analyses):\n",
    "    flat = set()\n",
    "    for p in analyses:\n",
    "        for part in (p.get(\"sp_morph_tag\") or \"\").split(\"/\"):\n",
    "            part = part.strip()\n",
    "            if part:\n",
    "                flat.add(part)\n",
    "    return sorted(flat)\n",
    "\n",
    "ROW_TMPL = (\n",
    "    \"<tr>\"\n",
    "    \"<td>{feat}</td>\"\n",
    "    \"<td>{known}</td>\"\n",
    "    \"<td>{gen}</td>\"\n",
    "    \"<td>{sim:.2f}</td>\"\n",
    "    \"<td>{wt}</td>\"\n",
    "    \"<td>{contrib:.2f}</td>\"\n",
    "    \"</tr>\"\n",
    ")\n",
    "\n",
    "def make_table(details):\n",
    "    parts = [\n",
    "        \"<tr>\"\n",
    "        \"<th>Feature</th><th>TF</th><th>Mph</th>\"\n",
    "        \"<th>Sim</th><th>Wt</th><th>Contrib</th>\"\n",
    "        \"</tr>\"\n",
    "    ]\n",
    "    total_raw = 0.0\n",
    "    total_wt  = 0\n",
    "    for feat, dv in details.items():\n",
    "        known   = html_mod.escape(str(dv[\"tag1\"] or \"\"))  #N1904-TF\n",
    "        gen     = html_mod.escape(str(dv[\"tag2\"] or \"\")) #Morpheus\n",
    "        sim     = dv[\"similarity\"]\n",
    "        wt      = dv[\"weight\"]\n",
    "        contrib = sim * wt\n",
    "        total_raw += contrib\n",
    "        total_wt  += wt\n",
    "        parts.append(ROW_TMPL.format(\n",
    "            feat=feat, known=known, gen=gen, sim=sim, wt=wt, contrib=contrib\n",
    "        ))\n",
    "    parts.append(\n",
    "        \"<tr style='font-weight:bold'>\"\n",
    "        f\"<td>Total</td><td></td><td></td><td></td>\"\n",
    "        f\"<td>{total_wt}</td><td>{total_raw:.2f}</td>\"\n",
    "        \"</tr>\"\n",
    "    )\n",
    "    norm = (total_raw/total_wt) if total_wt else 0.0\n",
    "    parts.append(\n",
    "        \"<tr style='font-weight:bold'>\"\n",
    "        f\"<td>Norm</td><td></td><td></td>\"\n",
    "        f\"<td>{norm:.3f}</td><td></td><td></td>\"\n",
    "        \"</tr>\"\n",
    "    )\n",
    "    return \"<table>\" + \"\".join(parts) + \"</table>\"\n",
    "\n",
    "def format_blocks(blocks):\n",
    "    if not blocks:\n",
    "        return \"<pre>empty</pre>\"\n",
    "    lines = []\n",
    "    for sub in blocks:\n",
    "        line = \", \".join(sub)\n",
    "        line = line.replace(\"\\t\", \"    \").replace(\":raw\", \"\\n:raw\")\n",
    "        lines.append(line.strip(\"'\"))\n",
    "    return \"<pre>\\n\" + \"\\n\".join(lines) + \"\\n</pre>\"\n",
    "\n",
    "# 3) Load tests\n",
    "tests = []\n",
    "with open(INPUT_FILE, newline=\"\", encoding=\"utf-8\") as f:\n",
    "    rdr = csv.reader(f, delimiter=\"\\t\")\n",
    "    for row in rdr:\n",
    "        if not row or row[0].startswith(\"#\"):\n",
    "            continue\n",
    "        tests.append({\n",
    "            \"expected_sp_tag\": row[0].strip(),\n",
    "            \"word_betacode\":  row[1].strip(),\n",
    "            \"lemma_betacode\":  row[1].strip()\n",
    "        })\n",
    "\n",
    "    # 4) Process and build entries\n",
    "    summary = {\"total\": len(tests), \"passed\":0, \"close\":0, \"failed\":0, \"no_block\":0}\n",
    "    entries = []\n",
    "\n",
    "    for item in tqdm(tests, desc=\"Processing words\"):\n",
    "        wb       = item[\"word_betacode\"]\n",
    "        expected = item[\"expected_sp_tag\"]\n",
    "        uni      = to_greek(wb)\n",
    "    \n",
    "        # fetch analyses\n",
    "        entry = fetch_analysis(wb)\n",
    "        blocks   = entry.get(\"blocks\", [])\n",
    "        analyses = entry.get(\"analyses\", [])\n",
    "        if not blocks:\n",
    "            summary[\"no_block\"] += 1\n",
    "    \n",
    "        # group by lemma_beta (strip '*')\n",
    "        lemma_groups = defaultdict(list)\n",
    "        for p in analyses:\n",
    "            key = (p.get(\"lemma_base3ta\") or \"\").replace(\"*\",\"\")\n",
    "            lemma_groups[key].append(p)\n",
    "    \n",
    "        # start this word’s HTML\n",
    "        html = []\n",
    "        html.append(f'<div id=\"entry-{wb}\">')\n",
    "        html.append(f'<h2><a href=\"https://www.perseus.tufts.edu/hopper/morph?l={wb}&la=greek\" target=\"_blank\">{wb} ({uni})</a></h2>')\n",
    "    \n",
    "        if not blocks:\n",
    "            html.append('<div class=\"no-block\">no Morpheus blocks</div>')\n",
    "            html.append('</div><hr/>')\n",
    "            entries.append(\"\\n\".join(html))\n",
    "            continue\n",
    "    \n",
    "        # per-lemma subentries\n",
    "        for lemma, parses in lemma_groups.items():\n",
    "            lemma_uni = to_greek(lemma)\n",
    "            tags      = flatten_tags(parses)\n",
    "    \n",
    "            # find best tag & score, stopping on perfect match\n",
    "            best_tag, best_score = None, -1.0\n",
    "            for t in tags:\n",
    "                sc = morphkit.compare_tags(expected, t, debug=False)[\"overall_similarity\"]\n",
    "                if sc > best_score:\n",
    "                    best_tag, best_score = t, sc\n",
    "                    if sc == 1.0:\n",
    "                        break\n",
    "    \n",
    "            # category\n",
    "            if best_score == 1.0:\n",
    "                cat, col = \"match\", \"green\"\n",
    "                summary[\"passed\"] += 1\n",
    "            elif best_score >= CLOSE_THRESH:\n",
    "                cat, col = \"close\", \"orange\"\n",
    "                summary[\"close\"] += 1\n",
    "            else:\n",
    "                cat, col = \"no-match\", \"red\"\n",
    "                summary[\"failed\"] += 1\n",
    "    \n",
    "            html.append(f'<div class=\"lemma-group {cat}\">')\n",
    "            if item[\"lemma_betacode\"]==lemma:\n",
    "                lemma_match='green'\n",
    "            else:\n",
    "                lemma_match='grey'\n",
    "            html.append(f'  <h3><span style=\"color:{lemma_match};\">Lemma: {lemma} ({lemma_uni})</span> <span style=\"color:{col};\">[{cat}]</span></h3>')\n",
    "            html.append('  <div><strong>Expected:</strong> '\n",
    "                        f'<a href=\"https://tonyjurg.github.io/Sandborg-Petersen-decoder/index.html?tag={expected}\" target=\"_blank\">{expected}</a></div>')\n",
    "    \n",
    "            # tooltip for best_tag\n",
    "            cmp_res = morphkit.compare_tags(expected, best_tag, debug=False)\n",
    "            table   = make_table(cmp_res[\"details\"])\n",
    "            html.append('  <div><strong>Morpheus:</strong> '\n",
    "                        f'<span class=\"tooltip\">{best_tag} : {best_score:.2f}'\n",
    "                        f'<div class=\"tooltip-content\"><h4>Tag: {best_tag}</h4>{table}</div>'\n",
    "                        '</span></div>')\n",
    "    \n",
    "            # show blocks & JSON only on non-perfect\n",
    "            if cat != \"match\":\n",
    "                html.append('  <details><summary>Blocks</summary>' + format_blocks(blocks) + '</details>')\n",
    "                html.append('  <details><summary>Analyses JSON</summary><pre>' +\n",
    "                            html_mod.escape(json.dumps(parses, indent=2, ensure_ascii=False)) +\n",
    "                            '</pre></details>')\n",
    "    \n",
    "            html.append('</div>')  # close lemma-group\n",
    "    \n",
    "        html.append('</div><hr/>')  # close entry\n",
    "        entries.append(\"\\n\".join(html))\n",
    "\n",
    "    # 5) Write out final HTML\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as out:\n",
    "        # write the header\n",
    "        out.write(f\"\"\"<!DOCTYPE html>\n",
    "        <html lang=\"en\">\n",
    "        <head><meta charset=\"utf-8\">\n",
    "        <title>SP-Tag Analysis</title>\n",
    "        <style>\n",
    "          body {{ font-family:sans-serif; padding:20px }}\n",
    "          .tooltip {{ position:relative; display:inline-block; cursor:help }}\n",
    "          .tooltip .tooltip-content {{ display:none; position:absolute; top:1.2em; left:0;\n",
    "            background:white; border:1px solid #ccc; padding:6px; z-index:100;\n",
    "            white-space:nowrap }}\n",
    "          .tooltip:hover .tooltip-content {{ display:block }}\n",
    "          .tooltip-content table {{ border-collapse:collapse; font-family:monospace; font-size:12px }}\n",
    "          .tooltip-content th, .tooltip-content td {{ border:1px solid #ddd; padding:2px 6px }}\n",
    "          .tooltip-content th {{ background:#f0f0f0 }}\n",
    "          .no-block {{ opacity:0.6; color:gray }}\n",
    "        </style>\n",
    "        </head>\n",
    "        <body>\n",
    "        <h1>SP-Tag Analysis Report</h1>\n",
    "        <ul>\n",
    "          <li>Total words: {summary['total']}</li>\n",
    "          <li>Passed: <span style=\"color:green;\">{summary['passed']}</span></li>\n",
    "          <li>Close: <span style=\"color:orange;\">{summary['close']}</span></li>\n",
    "          <li>Failed: <span style=\"color:red;\">{summary['failed']}</span></li>\n",
    "          <li>No blocks: <span style=\"color:gray;\">{summary['no_block']}</span></li>\n",
    "        </ul>\n",
    "        <hr/>\n",
    "        \"\"\")\n",
    "        \n",
    "        for e in entries:\n",
    "            out.write(e + \"\\n\")\n",
    "        \n",
    "        out.write(\"</body></html>\")\n",
    "\n",
    "print(f\"✅ Report written to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350b2d16-7c65-46e9-a692-184a383f1efa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 5 - Footnotes and attribution<a class=\"anchor\" id=\"bullet5\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "This Jupyter notebook used the following sources for the analysis and implementation:\n",
    "\n",
    "- [Greek Beta Code standard](https://stephanus.tlg.uci.edu/encoding/BCM.pdf)\n",
    "- [beta-code-py](https://github.com/perseids-tools/beta-code-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc205d6-451d-49bc-bc33-1e171a5e6c13",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6 - Required libraries<a class=\"anchor\" id=\"bullet6\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "The scripts in this notebook require the following Python libraries to be installed in the environment:\n",
    "\n",
    "    beta_code \n",
    "    json\n",
    "    os  \n",
    "    pathlib\n",
    "    re\n",
    "    requests\n",
    "    unicodedata\n",
    "\n",
    "You can install any missing library from within Jupyter Notebook using either`pip` or `pip3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039be1e-3147-40d8-8708-ac30a0a34bcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 7 - Notebook version<a class=\"anchor\" id=\"bullet7\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "<div style=\"float: left;\">\n",
    "  <table>\n",
    "    <tr>\n",
    "      <td><strong>Author</strong></td>\n",
    "      <td>Tony Jurg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Version</strong></td>\n",
    "      <td>1.1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Date</strong></td>\n",
    "      <td>8 May 2025</td>\n",
    "    </tr>\n",
    "  </table>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
